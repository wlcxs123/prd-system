from flask import Flask, request, jsonify, render_template, redirect, url_for, send_file, make_response, session, g
import sqlite3
import json
import os
from datetime import datetime, timedelta
import csv
from io import StringIO
import bcrypt
from functools import wraps
from flask_cors import CORS
from marshmallow import ValidationError
import time

from config import config
from validation import (
    validate_questionnaire_with_schema, 
    normalize_questionnaire_data, 
    quick_validate,
    create_validation_error_response
)
from question_types import (
    question_processor,
    process_complete_questionnaire,
    format_question_for_display
)
from error_handlers import (
    register_error_handlers,
    StandardErrorResponse,
    validation_error,
    auth_error,
    permission_error,
    not_found_error,
    server_error,
    business_error
)

def merge_questionnaire_data(original_data, update_data):
    """æ™ºèƒ½åˆå¹¶é—®å·æ•°æ®ï¼Œåªæ›´æ–°æ”¹åŠ¨çš„éƒ¨åˆ†"""
    import copy
    
    # æ·±æ‹·è´åŸå§‹æ•°æ®ä½œä¸ºåŸºç¡€
    merged = copy.deepcopy(original_data)
    
    # åˆå¹¶åŸºæœ¬ä¿¡æ¯
    if 'basic_info' in update_data:
        if 'basic_info' not in merged:
            merged['basic_info'] = {}
        merged['basic_info'].update(update_data['basic_info'])
    
    # åˆå¹¶é—®é¢˜æ•°æ®
    if 'questions' in update_data:
        if 'questions' not in merged:
            merged['questions'] = []
        
        # ç¡®ä¿merged['questions']æœ‰è¶³å¤Ÿçš„å…ƒç´ 
        while len(merged['questions']) < len(update_data['questions']):
            merged['questions'].append({})
        
        # é€ä¸ªæ›´æ–°é—®é¢˜
        for i, update_question in enumerate(update_data['questions']):
            if i < len(merged['questions']):
                # åªæ›´æ–°æœ‰å€¼çš„å­—æ®µ
                for key, value in update_question.items():
                    if value is not None and value != '':
                        merged['questions'][i][key] = value
            else:
                # æ–°å¢é—®é¢˜
                merged['questions'].append(update_question)
    
    # å¤„ç†å…¶ä»–å¯èƒ½çš„æ•°æ®ç»“æ„ï¼ˆdata, detailedDataç­‰ï¼‰
    for key in ['data', 'detailedData']:
        if key in update_data:
            if key not in merged:
                merged[key] = []
            
            if isinstance(update_data[key], list):
                # ç¡®ä¿merged[key]æœ‰è¶³å¤Ÿçš„å…ƒç´ 
                while len(merged[key]) < len(update_data[key]):
                    merged[key].append({})
                
                # é€ä¸ªæ›´æ–°å…ƒç´ 
                for i, update_item in enumerate(update_data[key]):
                    if i < len(merged[key]):
                        if isinstance(update_item, dict):
                            for field_key, field_value in update_item.items():
                                if field_value is not None and field_value != '':
                                    merged[key][i][field_key] = field_value
                        else:
                            merged[key][i] = update_item
                    else:
                        merged[key].append(update_item)
            else:
                merged[key] = update_data[key]
    
    # æ›´æ–°å…¶ä»–é¡¶çº§å­—æ®µ
    for key, value in update_data.items():
        if key not in ['basic_info', 'questions', 'data', 'detailedData'] and value is not None:
            merged[key] = value
    
    return merged

app = Flask(__name__, template_folder='templates', static_folder='static')

# åŠ è½½é…ç½®
config_name = os.environ.get('FLASK_ENV', 'development')
app.config.from_object(config[config_name])

# è®°å½•åº”ç”¨å¯åŠ¨æ—¶é—´ç”¨äºæ€§èƒ½ç›‘æ§
app.config['START_TIME'] = time.time()

# åŠ¨æ€baseUrlé…ç½®
def get_base_url():
    """æ ¹æ®ç¯å¢ƒåŠ¨æ€è·å–baseUrl"""
    # è·å–ä¸»æœºå
    hostname = os.environ.get('SERVER_NAME', '')
    
    # åˆ¤æ–­æ˜¯å¦ä¸ºæœ¬åœ°ç¯å¢ƒï¼šå¦‚æœæ²¡æœ‰è®¾ç½®SERVER_NAMEæˆ–è€…æ˜¯æœ¬åœ°åœ°å€
    is_local = (not hostname or 
                hostname in ['localhost', '127.0.0.1', '0.0.0.0'] or
                hostname.startswith('192.168.') or
                hostname.startswith('10.') or
                hostname.startswith('172.'))
    
    if is_local:
        # æœ¬åœ°ç¯å¢ƒä½¿ç”¨å®Œæ•´URLï¼Œç¡®ä¿å‰ç«¯å¯ä»¥æ­£ç¡®è·³è½¬
        port = os.environ.get('PORT', '5002')
        return f'http://127.0.0.1:{port}'
    else:
        # æœåŠ¡å™¨ç¯å¢ƒä½¿ç”¨å®Œæ•´URL
        port = os.environ.get('PORT', '5002')
        return f'http://{hostname}:{port}'

# å°†baseUrlæ·»åŠ åˆ°åº”ç”¨é…ç½®ä¸­
app.config['BASE_URL'] = get_base_url()

# å¯ç”¨CORSæ”¯æŒ - å¢å¼ºé…ç½®
CORS(app, resources={
    r"/api/*": {
        "origins": ["http://localhost:*", "http://127.0.0.1:*", "*"],
        "methods": ["GET", "POST", "PUT", "DELETE", "OPTIONS"],
        "allow_headers": ["Content-Type", "Authorization", "Accept"],
        "supports_credentials": True,
        "max_age": 3600
    }
})

# ==================== ä¸­é—´ä»¶ ====================

@app.before_request
def before_request():
    """è¯·æ±‚å‰å¤„ç† - ä¼šè¯ç®¡ç†ä¸­é—´ä»¶"""
    # è·³è¿‡é™æ€æ–‡ä»¶å’Œç™»å½•ç›¸å…³çš„è¯·æ±‚
    if (request.endpoint and 
        (request.endpoint.startswith('static') or 
         request.path in ['/api/auth/login', '/api/auth/status', '/login'] or
         request.path.startswith('/static/'))):
        return
    
    # å¯¹äºéœ€è¦è®¤è¯çš„APIè¯·æ±‚ï¼Œæ£€æŸ¥ä¼šè¯çŠ¶æ€
    if request.path.startswith('/api/') and 'user_id' in session:
        # æ£€æŸ¥ä¼šè¯è¶…æ—¶ï¼ˆä½†ä¸è‡ªåŠ¨æ¸…é™¤ï¼Œè®©è£…é¥°å™¨å¤„ç†ï¼‰
        timeout_seconds = app.config.get('PERMANENT_SESSION_LIFETIME', timedelta(hours=1)).total_seconds()
        current_time = time.time()
        last_activity = session.get('last_activity', current_time)
        
        # å¦‚æœä¼šè¯å³å°†è¿‡æœŸï¼ˆå‰©ä½™æ—¶é—´å°‘äº5åˆ†é’Ÿï¼‰ï¼Œåœ¨å“åº”å¤´ä¸­æ·»åŠ è­¦å‘Š
        if current_time - last_activity > timeout_seconds - 300:  # 5åˆ†é’Ÿè­¦å‘Š
            g.session_warning = True

@app.after_request
def after_request(response):
    """è¯·æ±‚åå¤„ç† - æ·»åŠ ä¼šè¯è­¦å‘Šå¤´"""
    if hasattr(g, 'session_warning') and g.session_warning:
        response.headers['X-Session-Warning'] = 'Session will expire soon'
        
        # å¦‚æœæ˜¯JSONå“åº”ï¼Œæ·»åŠ è­¦å‘Šä¿¡æ¯
        if response.content_type and 'application/json' in response.content_type:
            try:
                data = response.get_json()
                if isinstance(data, dict) and data.get('success'):
                    data['session_warning'] = 'ä¼šè¯å³å°†è¿‡æœŸï¼Œè¯·åŠæ—¶åˆ·æ–°'
                    response.data = json.dumps(data, default=str, ensure_ascii=False)
            except:
                pass  # å¦‚æœæ— æ³•è§£æJSONï¼Œå¿½ç•¥è­¦å‘Š
    
    return response

# æ•°æ®åº“é…ç½®
DATABASE = app.config['DATABASE_PATH']

# åˆå§‹åŒ–æ•°æ®åº“
def init_db():
    """åˆå§‹åŒ–æ•°æ®åº“ï¼Œåˆ›å»ºæ‰€æœ‰å¿…è¦çš„è¡¨"""
    with sqlite3.connect(DATABASE) as conn:
        cursor = conn.cursor()
        
        # åˆ›å»ºé—®å·æ•°æ®è¡¨ - æ ¹æ®è®¾è®¡æ–‡æ¡£æ›´æ–°
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS questionnaires (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            type TEXT NOT NULL,
            name TEXT,
            grade TEXT,
            submission_date DATE,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            data TEXT NOT NULL,
            report_data TEXT,
            report_generated_at TIMESTAMP,
            parent_phone TEXT,
            parent_wechat TEXT,
            parent_email TEXT,
            gender TEXT,
            birthdate TEXT,
            school TEXT,
            teacher TEXT
        )
        ''')
        
        # æ£€æŸ¥å¹¶æ·»åŠ æ–°å­—æ®µï¼ˆç”¨äºæ•°æ®åº“å‡çº§ï¼‰
        try:
            cursor.execute("ALTER TABLE questionnaires ADD COLUMN report_data TEXT")
        except sqlite3.OperationalError:
            pass  # å­—æ®µå·²å­˜åœ¨
        
        try:
            cursor.execute("ALTER TABLE questionnaires ADD COLUMN report_generated_at TIMESTAMP")
        except sqlite3.OperationalError:
            pass  # å­—æ®µå·²å­˜åœ¨
        
        # æ·»åŠ å®¶é•¿è”ç³»æ–¹å¼å­—æ®µ
        try:
            cursor.execute("ALTER TABLE questionnaires ADD COLUMN parent_phone TEXT")
        except sqlite3.OperationalError:
            pass  # å­—æ®µå·²å­˜åœ¨
        
        try:
            cursor.execute("ALTER TABLE questionnaires ADD COLUMN parent_wechat TEXT")
        except sqlite3.OperationalError:
            pass  # å­—æ®µå·²å­˜åœ¨
        
        try:
            cursor.execute("ALTER TABLE questionnaires ADD COLUMN parent_email TEXT")
        except sqlite3.OperationalError:
            pass  # å­—æ®µå·²å­˜åœ¨
        
        # æ·»åŠ æ€§åˆ«å’Œå‡ºç”Ÿæ—¥æœŸå­—æ®µ
        try:
            cursor.execute("ALTER TABLE questionnaires ADD COLUMN gender TEXT")
        except sqlite3.OperationalError:
            pass  # å­—æ®µå·²å­˜åœ¨
        
        try:
            cursor.execute("ALTER TABLE questionnaires ADD COLUMN birthdate TEXT")
        except sqlite3.OperationalError:
            pass  # å­—æ®µå·²å­˜åœ¨
        
        # æ·»åŠ å­¦æ ¡å’Œè€å¸ˆå­—æ®µ
        try:
            cursor.execute("ALTER TABLE questionnaires ADD COLUMN school TEXT")
        except sqlite3.OperationalError:
            pass  # å­—æ®µå·²å­˜åœ¨
        
        try:
            cursor.execute("ALTER TABLE questionnaires ADD COLUMN teacher TEXT")
        except sqlite3.OperationalError:
            pass  # å­—æ®µå·²å­˜åœ¨
        
        # åˆ›å»ºç”¨æˆ·è®¤è¯è¡¨
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS users (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            username TEXT UNIQUE NOT NULL,
            password_hash TEXT NOT NULL,
            role TEXT DEFAULT 'admin',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            last_login TIMESTAMP
        )
        ''')
        
        # åˆ›å»ºæ“ä½œæ—¥å¿—è¡¨
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS operation_logs (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER,
            operation TEXT NOT NULL,
            target_id INTEGER,
            details TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (user_id) REFERENCES users (id)
        )
        ''')
        
        # åˆ›å»ºé»˜è®¤ç®¡ç†å‘˜ç”¨æˆ·ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        cursor.execute("SELECT COUNT(*) FROM users WHERE username = 'admin'")
        if cursor.fetchone()[0] == 0:
            # é»˜è®¤å¯†ç : admin123
            password_hash = bcrypt.hashpw('admin123'.encode('utf-8'), bcrypt.gensalt())
            cursor.execute(
                "INSERT INTO users (username, password_hash, role) VALUES (?, ?, ?)",
                ('admin', password_hash.decode('utf-8'), 'admin')
            )
        
        conn.commit()
        print("æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")

# è·å–æ•°æ®åº“è¿æ¥
def get_db():
    conn = sqlite3.connect(DATABASE)
    conn.row_factory = sqlite3.Row
    return conn

# ==================== ä¼šè¯ç®¡ç†å’Œæƒé™æ§åˆ¶ ====================

def check_session_timeout():
    """æ£€æŸ¥ä¼šè¯æ˜¯å¦è¶…æ—¶"""
    if 'user_id' in session:
        # æ£€æŸ¥ä¼šè¯æ˜¯å¦è®¾ç½®äº†æœ€åæ´»åŠ¨æ—¶é—´
        if 'last_activity' not in session:
            session['last_activity'] = time.time()
            return True
        
        # è®¡ç®—ä¼šè¯è¶…æ—¶æ—¶é—´ï¼ˆä»é…ç½®ä¸­è·å–ï¼Œé»˜è®¤1å°æ—¶ï¼‰
        timeout_seconds = app.config.get('PERMANENT_SESSION_LIFETIME', timedelta(hours=1)).total_seconds()
        current_time = time.time()
        last_activity = session.get('last_activity', current_time)
        
        # å¦‚æœè¶…æ—¶ï¼Œæ¸…é™¤ä¼šè¯
        if current_time - last_activity > timeout_seconds:
            user_id = session.get('user_id')
            username = session.get('username')
            
            # è®°å½•è‡ªåŠ¨ç™»å‡ºæ—¥å¿—
            if user_id:
                OperationLogger.log(OperationLogger.AUTO_LOGOUT, user_id, f'ç”¨æˆ· {username} ä¼šè¯è¶…æ—¶è‡ªåŠ¨ç™»å‡º')
            
            session.clear()
            return False
        
        # æ›´æ–°æœ€åæ´»åŠ¨æ—¶é—´
        session['last_activity'] = current_time
        return True
    
    return False

def update_session_activity():
    """æ›´æ–°ä¼šè¯æ´»åŠ¨æ—¶é—´"""
    if 'user_id' in session:
        session['last_activity'] = time.time()

# è®¤è¯è£…é¥°å™¨
def login_required(f):
    """è¦æ±‚ç”¨æˆ·ç™»å½•çš„è£…é¥°å™¨ - å¢å¼ºç‰ˆæœ¬ï¼ŒåŒ…å«ä¼šè¯è¶…æ—¶æ£€æŸ¥"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        # æ£€æŸ¥ä¼šè¯è¶…æ—¶
        if not check_session_timeout():
            # å¦‚æœæ˜¯APIè¯·æ±‚ï¼Œè¿”å›JSONé”™è¯¯
            if request.path.startswith('/api/'):
                return jsonify({
                    'success': False, 
                    'error': {
                        'code': 'SESSION_EXPIRED',
                        'message': 'ä¼šè¯å·²è¿‡æœŸï¼Œè¯·é‡æ–°ç™»å½•'
                    }
                }), 401
            # å¦‚æœæ˜¯é¡µé¢è¯·æ±‚ï¼Œé‡å®šå‘åˆ°ç™»å½•é¡µé¢
            else:
                return redirect(url_for('login_page'))
        
        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ç™»å½•
        if 'user_id' not in session:
            # å¦‚æœæ˜¯APIè¯·æ±‚ï¼Œè¿”å›JSONé”™è¯¯
            if request.path.startswith('/api/'):
                return jsonify({
                    'success': False, 
                    'error': {
                        'code': 'AUTH_REQUIRED',
                        'message': 'éœ€è¦ç™»å½•'
                    }
                }), 401
            # å¦‚æœæ˜¯é¡µé¢è¯·æ±‚ï¼Œé‡å®šå‘åˆ°ç™»å½•é¡µé¢
            else:
                return redirect(url_for('login_page'))
        
        # æ›´æ–°ä¼šè¯æ´»åŠ¨æ—¶é—´
        update_session_activity()
        
        return f(*args, **kwargs)
    return decorated_function

def admin_required(f):
    """è¦æ±‚ç®¡ç†å‘˜æƒé™çš„è£…é¥°å™¨ - å¢å¼ºç‰ˆæœ¬ï¼ŒåŒ…å«ä¼šè¯è¶…æ—¶å’Œæƒé™æ£€æŸ¥"""
    @wraps(f)
    def decorated_function(*args, **kwargs):
        # æ£€æŸ¥ä¼šè¯è¶…æ—¶
        if not check_session_timeout():
            return jsonify({
                'success': False, 
                'error': {
                    'code': 'SESSION_EXPIRED',
                    'message': 'ä¼šè¯å·²è¿‡æœŸï¼Œè¯·é‡æ–°ç™»å½•'
                }
            }), 401
        
        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ç™»å½•
        if 'user_id' not in session:
            return jsonify({
                'success': False, 
                'error': {
                    'code': 'AUTH_REQUIRED',
                    'message': 'éœ€è¦ç™»å½•'
                }
            }), 401
        
        # æ£€æŸ¥ç®¡ç†å‘˜æƒé™
        user_role = session.get('user_role')
        if user_role != 'admin':
            # è®°å½•æƒé™ä¸è¶³çš„å°è¯•
            OperationLogger.log(OperationLogger.ACCESS_DENIED, session.get('user_id'), 
                         f'ç”¨æˆ·å°è¯•è®¿é—®éœ€è¦ç®¡ç†å‘˜æƒé™çš„èµ„æº: {request.path}')
            
            return jsonify({
                'success': False, 
                'error': {
                    'code': 'PERMISSION_DENIED',
                    'message': 'æƒé™ä¸è¶³ï¼Œéœ€è¦ç®¡ç†å‘˜æƒé™'
                }
            }), 403
        
        # æ›´æ–°ä¼šè¯æ´»åŠ¨æ—¶é—´
        update_session_activity()
        
        return f(*args, **kwargs)
    return decorated_function

def validate_session_integrity():
    """éªŒè¯ä¼šè¯å®Œæ•´æ€§"""
    if 'user_id' in session:
        user_id = session.get('user_id')
        
        # éªŒè¯ç”¨æˆ·æ˜¯å¦ä»ç„¶å­˜åœ¨ä¸”æœ‰æ•ˆ
        try:
            with get_db() as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT id, username, role FROM users WHERE id = ?", (user_id,))
                user = cursor.fetchone()
                
                if not user:
                    # ç”¨æˆ·ä¸å­˜åœ¨ï¼Œæ¸…é™¤ä¼šè¯
                    session.clear()
                    return False
                
                # æ›´æ–°ä¼šè¯ä¸­çš„ç”¨æˆ·ä¿¡æ¯ï¼ˆé˜²æ­¢æƒé™å˜æ›´åä»ä½¿ç”¨æ—§æƒé™ï¼‰
                session['username'] = user['username']
                session['user_role'] = user['role']
                
                return True
        except Exception as e:
            print(f"éªŒè¯ä¼šè¯å®Œæ•´æ€§å¤±è´¥: {e}")
            session.clear()
            return False
    
    return False

# ==================== æ“ä½œæ—¥å¿—ç³»ç»Ÿ ====================

class OperationLogger:
    """æ“ä½œæ—¥å¿—è®°å½•å™¨"""
    
    # æ“ä½œç±»å‹å¸¸é‡
    LOGIN = 'LOGIN'
    LOGOUT = 'LOGOUT'
    AUTO_LOGOUT = 'AUTO_LOGOUT'
    CREATE_QUESTIONNAIRE = 'CREATE_QUESTIONNAIRE'
    UPDATE_QUESTIONNAIRE = 'UPDATE_QUESTIONNAIRE'
    DELETE_QUESTIONNAIRE = 'DELETE_QUESTIONNAIRE'
    BATCH_DELETE = 'BATCH_DELETE'
    VIEW_QUESTIONNAIRE = 'VIEW_QUESTIONNAIRE'
    EXPORT_DATA = 'EXPORT_DATA'
    ACCESS_DENIED = 'ACCESS_DENIED'
    EXTEND_SESSION = 'EXTEND_SESSION'
    SYSTEM_ERROR = 'SYSTEM_ERROR'
    
    # æ•æ„Ÿæ“ä½œåˆ—è¡¨
    SENSITIVE_OPERATIONS = {
        DELETE_QUESTIONNAIRE, BATCH_DELETE, EXPORT_DATA, 
        EXTEND_SESSION, ACCESS_DENIED
    }
    
    @staticmethod
    def log(operation, target_id=None, details=None, ip_address=None, user_agent=None):
        """è®°å½•æ“ä½œæ—¥å¿—"""
        try:
            user_id = session.get('user_id')
            username = session.get('username', 'anonymous')
            
            # è·å–è¯·æ±‚ä¿¡æ¯
            if not ip_address:
                ip_address = request.remote_addr or 'unknown'
            if not user_agent:
                user_agent = request.headers.get('User-Agent', 'unknown')[:500]  # é™åˆ¶é•¿åº¦
            
            # æ„å»ºè¯¦ç»†ä¿¡æ¯
            log_details = {
                'operation': operation,
                'user_details': details or '',
                'ip_address': ip_address,
                'user_agent': user_agent,
                'timestamp': datetime.now().isoformat(),
                'request_path': request.path if request else 'unknown',
                'request_method': request.method if request else 'unknown'
            }
            
            # å¯¹äºæ•æ„Ÿæ“ä½œï¼Œè®°å½•æ›´å¤šä¿¡æ¯
            if operation in OperationLogger.SENSITIVE_OPERATIONS:
                log_details['sensitive'] = True
                log_details['session_id'] = session.get('_id', 'unknown')
            
            with get_db() as conn:
                cursor = conn.cursor()
                cursor.execute(
                    "INSERT INTO operation_logs (user_id, operation, target_id, details) VALUES (?, ?, ?, ?)",
                    (user_id, operation, target_id, json.dumps(log_details, default=str, ensure_ascii=False))
                )
                conn.commit()
                
        except Exception as e:
            # è®°å½•æ—¥å¿—å¤±è´¥ä¸åº”è¯¥å½±å“ä¸»è¦åŠŸèƒ½
            print(f"è®°å½•æ“ä½œæ—¥å¿—å¤±è´¥: {e}")
            
            # å°è¯•è®°å½•åˆ°æ–‡ä»¶ä½œä¸ºå¤‡ä»½
            try:
                log_file = os.path.join(os.path.dirname(__file__), 'logs', 'operation_errors.log')
                os.makedirs(os.path.dirname(log_file), exist_ok=True)
                
                with open(log_file, 'a', encoding='utf-8') as f:
                    f.write(f"{datetime.now().isoformat()} - æ—¥å¿—è®°å½•å¤±è´¥: {e}\n")
                    f.write(f"æ“ä½œ: {operation}, ç”¨æˆ·: {username}, è¯¦æƒ…: {details}\n\n")
            except:
                pass  # å¦‚æœæ–‡ä»¶è®°å½•ä¹Ÿå¤±è´¥ï¼Œåˆ™å¿½ç•¥
    
    @staticmethod
    def log_system_event(event_type, details=None):
        """è®°å½•ç³»ç»Ÿäº‹ä»¶ï¼ˆæ— ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼‰"""
        try:
            log_details = {
                'event_type': event_type,
                'details': details or '',
                'timestamp': datetime.now().isoformat(),
                'system_event': True
            }
            
            with get_db() as conn:
                cursor = conn.cursor()
                cursor.execute(
                    "INSERT INTO operation_logs (user_id, operation, target_id, details) VALUES (?, ?, ?, ?)",
                    (None, f'SYSTEM_{event_type}', None, json.dumps(log_details, default=str, ensure_ascii=False))
                )
                conn.commit()
                
        except Exception as e:
            print(f"è®°å½•ç³»ç»Ÿäº‹ä»¶å¤±è´¥: {e}")

# å…¼å®¹æ€§å‡½æ•°
def log_operation(operation, target_id=None, details=None):
    """è®°å½•ç”¨æˆ·æ“ä½œæ—¥å¿— - å…¼å®¹æ€§å‡½æ•°"""
    OperationLogger.log(operation, target_id, details)

# ==================== è®¤è¯ç›¸å…³API ====================

@app.route('/api/auth/login', methods=['POST'])
def login():
    """ç”¨æˆ·ç™»å½•æ¥å£"""
    try:
        data = request.json
        
        if not data:
            response_data, status_code = validation_error(['è¯·æ±‚æ•°æ®ä¸èƒ½ä¸ºç©º'])
            return jsonify(response_data), status_code
        
        username = data.get('username', '').strip()
        password = data.get('password', '')
        
        if not username or not password:
            response_data, status_code = validation_error(['ç”¨æˆ·åå’Œå¯†ç ä¸èƒ½ä¸ºç©º'])
            return jsonify(response_data), status_code
        
        # æŸ¥è¯¢ç”¨æˆ·
        with get_db() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM users WHERE username = ?", (username,))
            user = cursor.fetchone()
        
        if not user:
            response_data, status_code = auth_error('ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯')
            return jsonify(response_data), status_code
        
        # éªŒè¯å¯†ç 
        if not bcrypt.checkpw(password.encode('utf-8'), user['password_hash'].encode('utf-8')):
            response_data, status_code = auth_error('ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯')
            return jsonify(response_data), status_code
        
        # åˆ›å»ºä¼šè¯
        session['user_id'] = user['id']
        session['username'] = user['username']
        session['user_role'] = user['role']
        session['last_activity'] = time.time()
        session['login_time'] = time.time()
        session.permanent = True
        
        # æ›´æ–°æœ€åç™»å½•æ—¶é—´
        with get_db() as conn:
            cursor = conn.cursor()
            cursor.execute(
                "UPDATE users SET last_login = ? WHERE id = ?",
                (datetime.now().strftime('%Y-%m-%d %H:%M:%S'), user['id'])
            )
            conn.commit()
        
        # è®°å½•ç™»å½•æ—¥å¿—
        OperationLogger.log(OperationLogger.LOGIN, user['id'], f'ç”¨æˆ· {username} ç™»å½•ç³»ç»Ÿ')
        
        return jsonify({
            'success': True,
            'message': 'ç™»å½•æˆåŠŸ',
            'user': {
                'id': user['id'],
                'username': user['username'],
                'role': user['role']
            },
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        response_data, status_code = server_error('ç™»å½•å¤±è´¥', str(e))
        return jsonify(response_data), status_code

@app.route('/api/auth/logout', methods=['POST'])
def logout():
    """ç”¨æˆ·ç™»å‡ºæ¥å£"""
    try:
        user_id = session.get('user_id')
        username = session.get('username')
        
        # è®°å½•ç™»å‡ºæ—¥å¿—
        if user_id:
            OperationLogger.log(OperationLogger.LOGOUT, user_id, f'ç”¨æˆ· {username} ç™»å‡ºç³»ç»Ÿ')
        
        # æ¸…é™¤ä¼šè¯
        session.clear()
        
        return jsonify({
            'success': True,
            'message': 'ç™»å‡ºæˆåŠŸ',
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': {
                'code': 'SERVER_ERROR',
                'message': 'ç™»å‡ºå¤±è´¥',
                'details': str(e)
            }
        }), 500

@app.route('/api/auth/status', methods=['GET'])
def auth_status():
    """æ£€æŸ¥ç™»å½•çŠ¶æ€æ¥å£ - å¢å¼ºç‰ˆæœ¬ï¼ŒåŒ…å«ä¼šè¯è¶…æ—¶æ£€æŸ¥"""
    try:
        # æ£€æŸ¥ä¼šè¯è¶…æ—¶
        if not check_session_timeout():
            return jsonify({
                'success': True,
                'authenticated': False,
                'user': None,
                'session_expired': True
            })
        
        # éªŒè¯ä¼šè¯å®Œæ•´æ€§
        if not validate_session_integrity():
            return jsonify({
                'success': True,
                'authenticated': False,
                'user': None,
                'session_invalid': True
            })
        
        if 'user_id' in session:
            # è®¡ç®—ä¼šè¯å‰©ä½™æ—¶é—´
            timeout_seconds = app.config.get('PERMANENT_SESSION_LIFETIME', timedelta(hours=1)).total_seconds()
            last_activity = session.get('last_activity', time.time())
            remaining_time = timeout_seconds - (time.time() - last_activity)
            
            return jsonify({
                'success': True,
                'authenticated': True,
                'user': {
                    'id': session['user_id'],
                    'username': session['username'],
                    'role': session['user_role']
                },
                'session_info': {
                    'remaining_time': max(0, int(remaining_time)),
                    'last_activity': datetime.fromtimestamp(last_activity).isoformat(),
                    'expires_at': datetime.fromtimestamp(last_activity + timeout_seconds).isoformat()
                }
            })
        else:
            return jsonify({
                'success': True,
                'authenticated': False,
                'user': None
            })
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': {
                'code': 'SERVER_ERROR',
                'message': 'æ£€æŸ¥ç™»å½•çŠ¶æ€å¤±è´¥',
                'details': str(e)
            }
        }), 500

@app.route('/api/auth/refresh', methods=['POST'])
@login_required
def refresh_session():
    """åˆ·æ–°ä¼šè¯æ¥å£"""
    try:
        # æ›´æ–°ä¼šè¯æ´»åŠ¨æ—¶é—´
        update_session_activity()
        
        # éªŒè¯ä¼šè¯å®Œæ•´æ€§
        if not validate_session_integrity():
            return jsonify({
                'success': False,
                'error': {
                    'code': 'SESSION_INVALID',
                    'message': 'ä¼šè¯æ— æ•ˆï¼Œè¯·é‡æ–°ç™»å½•'
                }
            }), 401
        
        # è®¡ç®—ä¼šè¯å‰©ä½™æ—¶é—´
        timeout_seconds = app.config.get('PERMANENT_SESSION_LIFETIME', timedelta(hours=1)).total_seconds()
        last_activity = session.get('last_activity', time.time())
        remaining_time = timeout_seconds - (time.time() - last_activity)
        
        return jsonify({
            'success': True,
            'message': 'ä¼šè¯å·²åˆ·æ–°',
            'session_info': {
                'remaining_time': max(0, int(remaining_time)),
                'last_activity': datetime.fromtimestamp(last_activity).isoformat(),
                'expires_at': datetime.fromtimestamp(last_activity + timeout_seconds).isoformat()
            },
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': {
                'code': 'SERVER_ERROR',
                'message': 'åˆ·æ–°ä¼šè¯å¤±è´¥',
                'details': str(e)
            }
        }), 500

@app.route('/api/auth/extend', methods=['POST'])
@admin_required
def extend_session():
    """å»¶é•¿ä¼šè¯æ¥å£ï¼ˆä»…ç®¡ç†å‘˜ï¼‰"""
    try:
        data = request.json or {}
        extend_minutes = data.get('minutes', 60)  # é»˜è®¤å»¶é•¿60åˆ†é’Ÿ
        
        # é™åˆ¶å»¶é•¿æ—¶é—´ï¼ˆæœ€å¤š4å°æ—¶ï¼‰
        if extend_minutes > 240:
            extend_minutes = 240
        
        # æ›´æ–°ä¼šè¯æ´»åŠ¨æ—¶é—´ï¼Œç›¸å½“äºå»¶é•¿ä¼šè¯
        session['last_activity'] = time.time() + (extend_minutes * 60)
        
        # è®°å½•ä¼šè¯å»¶é•¿æ“ä½œ
        OperationLogger.log(OperationLogger.EXTEND_SESSION, session.get('user_id'), 
                     f'ç®¡ç†å‘˜å»¶é•¿ä¼šè¯ {extend_minutes} åˆ†é’Ÿ')
        
        return jsonify({
            'success': True,
            'message': f'ä¼šè¯å·²å»¶é•¿ {extend_minutes} åˆ†é’Ÿ',
            'extended_minutes': extend_minutes,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': {
                'code': 'SERVER_ERROR',
                'message': 'å»¶é•¿ä¼šè¯å¤±è´¥',
                'details': str(e)
            }
        }), 500

# ä½¿ç”¨æ–°çš„éªŒè¯æ¨¡å—æ›¿æ¢åŸæœ‰çš„éªŒè¯å‡½æ•°
def validate_questionnaire_data(data):
    """éªŒè¯é—®å·æ•°æ®æ ¼å¼ - ä½¿ç”¨æ–°çš„éªŒè¯æ¨¡å—"""
    return quick_validate(data)

# é—®å·æäº¤API - ä»»åŠ¡4.1è¦æ±‚çš„ç«¯ç‚¹
@app.route('/api/submit', methods=['POST'])
def submit_questionnaire_legacy():
    """é—®å·æäº¤æ¥å£ - å…¼å®¹æ—§ç‰ˆæœ¬APIè·¯å¾„"""
    return submit_questionnaire()

# ä¿å­˜é—®å·æ•°æ® - æ ‡å‡†åŒ–APIè·¯å¾„
@app.route('/api/questionnaires', methods=['POST'])
def submit_questionnaire():
    try:
        data = request.json
        
        if not data:
            response_data, status_code = validation_error(['è¯·æ±‚æ•°æ®ä¸èƒ½ä¸ºç©º'])
            return jsonify(response_data), status_code
        
        # æ•°æ®æ ‡å‡†åŒ–
        try:
            normalized_data = normalize_questionnaire_data(data)
        except Exception as e:
            response_data, status_code = validation_error([f'æ•°æ®æ ‡å‡†åŒ–å¤±è´¥: {str(e)}'])
            return jsonify(response_data), status_code
        
        # ä½¿ç”¨æ–°çš„éªŒè¯æ¨¡å—è¿›è¡ŒéªŒè¯
        is_valid, validation_errors, validated_data = validate_questionnaire_with_schema(normalized_data)
        
        if not is_valid:
            response_data, status_code = validation_error(validation_errors)
            return jsonify(response_data), status_code
        
        # ä»éªŒè¯åçš„æ•°æ®ä¸­æå–åŸºæœ¬ä¿¡æ¯
        questionnaire_type = validated_data.get('type', 'unknown')
        basic_info = validated_data.get('basic_info', {})
        
        # è°ƒè¯•è¾“å‡º
        print("\n" + "=" * 80)
        print("ğŸ” DEBUG: é—®å·æäº¤è°ƒè¯•ä¿¡æ¯")
        print("=" * 80)
        print(f"DEBUG: Complete basic_info content: {basic_info}")
        print(f"DEBUG: basic_info keys: {list(basic_info.keys())}")
        print(f"ğŸ“‹ validated_data keys: {list(validated_data.keys())}")
        print(f"ğŸ“‹ basic_info keys: {list(basic_info.keys()) if basic_info else 'None'}")
        print(f"ğŸ‘¤ validated_data gender: '{validated_data.get('gender')}'")
        print(f"ğŸ‚ validated_data birthdate: '{validated_data.get('birthdate')}'")
        if basic_info:
            print(f"ğŸ‘¤ basic_info gender: '{basic_info.get('gender')}'")
            print(f"ğŸ‚ basic_info birthdate: '{basic_info.get('birthdate')}'")
            print(f"ğŸ‚ basic_info birth_date: '{basic_info.get('birth_date')}'")
        print("=" * 80 + "\n")
        
        name = basic_info.get('name', '') or validated_data.get('name', '')
        grade = basic_info.get('grade', '') or validated_data.get('grade', '')
        submission_date = basic_info.get('submission_date', datetime.now().strftime('%Y-%m-%d'))
        
        # æå–å®¶é•¿è”ç³»æ–¹å¼
        parent_phone = basic_info.get('parent_phone', '') or validated_data.get('parent_phone', '')
        parent_wechat = basic_info.get('parent_wechat', '') or validated_data.get('parent_wechat', '')
        parent_email = basic_info.get('parent_email', '') or validated_data.get('parent_email', '')
        
        # æå–æ€§åˆ«å’Œå‡ºç”Ÿæ—¥æœŸï¼Œä¼˜å…ˆä»basic_infoè·å–ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä»é¡¶çº§å­—æ®µè·å–
        gender = basic_info.get('gender', '') or validated_data.get('gender', '')
        birthdate = basic_info.get('birthdate', '') or basic_info.get('birth_date', '') or validated_data.get('birthdate', '') or validated_data.get('birth_date', '')
        
        # æå–å­¦æ ¡å’Œè€å¸ˆä¿¡æ¯
        school = basic_info.get('school', '') or validated_data.get('school', '')
        teacher = basic_info.get('teacher', '') or validated_data.get('teacher', '')
        
        # æå–æ–°å¢å­—æ®µ
        school_name = basic_info.get('school_name', '')
        admission_date = basic_info.get('admission_date', '')
        address = basic_info.get('address', '')
        filler_name = basic_info.get('filler_name', '')
        fill_date = basic_info.get('fill_date', '')
        
        print(f"DEBUG: Final extracted values - gender: '{gender}', birthdate: '{birthdate}', school: '{school}', teacher: '{teacher}'")
        print(f"DEBUG: New fields - school_name: '{school_name}', admission_date: '{admission_date}', address: '{address}', filler_name: '{filler_name}', fill_date: '{fill_date}'")
        
        # å§‹ç»ˆä½¿ç”¨æœåŠ¡å™¨å½“å‰æ—¶é—´ä½œä¸ºåˆ›å»ºæ—¶é—´
        created_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # ä½¿ç”¨é—®é¢˜ç±»å‹å¤„ç†å™¨è¿›è¡Œæœ€ç»ˆå¤„ç†
        final_data = process_complete_questionnaire(validated_data)
        
        # å°†å¤„ç†åçš„æ•°æ®ä¿å­˜åˆ°æ•°æ®åº“
        with get_db() as conn:
            cursor = conn.cursor()
            cursor.execute(
                "INSERT INTO questionnaires (type, name, grade, submission_date, created_at, updated_at, data, parent_phone, parent_wechat, parent_email, gender, birthdate, school, teacher, school_name, admission_date, address, filler_name) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)",
                (questionnaire_type, name, grade, submission_date, created_at, created_at, json.dumps(final_data, default=str, ensure_ascii=False), parent_phone, parent_wechat, parent_email, gender, birthdate, school, teacher, school_name, admission_date, address, filler_name)
            )
            conn.commit()
            questionnaire_id = cursor.lastrowid
        
        # è®°å½•æ“ä½œæ—¥å¿—
        OperationLogger.log(OperationLogger.CREATE_QUESTIONNAIRE, questionnaire_id, f'åˆ›å»ºé—®å·: {name} - {questionnaire_type}')
        
        return jsonify({
            'success': True, 
            'id': questionnaire_id,
            'message': 'é—®å·æäº¤æˆåŠŸ',
            'timestamp': datetime.now().isoformat()
        }), 201
        
    except ValidationError as e:
        response_data, status_code = validation_error(e.messages)
        return jsonify(response_data), status_code
    except Exception as e:
        response_data, status_code = server_error('é—®å·æäº¤å¤±è´¥', str(e))
        return jsonify(response_data), status_code

# è·å–æ‰€æœ‰é—®å·æ•°æ® - å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒåˆ†é¡µå’Œé«˜çº§æœç´¢
@app.route('/api/questionnaires', methods=['GET'])
@login_required
def get_questionnaires():
    try:
        # è·å–æŸ¥è¯¢å‚æ•°
        page = int(request.args.get('page', 1))
        limit = min(int(request.args.get('limit', 20)), 100)  # é™åˆ¶æœ€å¤§æ¯é¡µæ•°é‡
        search = request.args.get('search', '').strip()
        
        # é«˜çº§ç­›é€‰å‚æ•°
        questionnaire_type = request.args.get('type', '').strip()
        grade_filter = request.args.get('grade', '').strip()
        date_from = request.args.get('date_from', '').strip()
        date_to = request.args.get('date_to', '').strip()
        sort_by = request.args.get('sort_by', 'created_at')  # æ’åºå­—æ®µ
        sort_order = request.args.get('sort_order', 'desc')  # æ’åºæ–¹å‘
        
        # éªŒè¯æ’åºå‚æ•°
        valid_sort_fields = ['id', 'name', 'type', 'grade', 'submission_date', 'created_at', 'updated_at']
        if sort_by not in valid_sort_fields:
            sort_by = 'created_at'
        
        if sort_order.lower() not in ['asc', 'desc']:
            sort_order = 'desc'
        
        with get_db() as conn:
            cursor = conn.cursor()
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            where_conditions = []
            params = []
            
            # åŸºæœ¬æœç´¢ - æœç´¢å§“åã€ç±»å‹ã€å¹´çº§
            if search:
                where_conditions.append("(name LIKE ? OR type LIKE ? OR grade LIKE ?)")
                search_param = f"%{search}%"
                params.extend([search_param, search_param, search_param])
            
            # é—®å·ç±»å‹ç­›é€‰
            if questionnaire_type:
                where_conditions.append("type = ?")
                params.append(questionnaire_type)
            
            # å¹´çº§ç­›é€‰
            if grade_filter:
                where_conditions.append("grade = ?")
                params.append(grade_filter)
            
            # æ—¥æœŸèŒƒå›´ç­›é€‰
            if date_from:
                where_conditions.append("DATE(created_at) >= ?")
                params.append(date_from)
            
            if date_to:
                where_conditions.append("DATE(created_at) <= ?")
                params.append(date_to)
            
            # æ„å»ºå®Œæ•´çš„WHEREå­å¥
            where_clause = ""
            if where_conditions:
                where_clause = "WHERE " + " AND ".join(where_conditions)
            
            # è·å–æ€»æ•°
            count_query = f"SELECT COUNT(*) FROM questionnaires {where_clause}"
            cursor.execute(count_query, params)
            total_count = cursor.fetchone()[0]
            
            # è·å–åˆ†é¡µæ•°æ®
            offset = (page - 1) * limit
            query = f"SELECT * FROM questionnaires {where_clause} ORDER BY {sort_by} {sort_order.upper()} LIMIT ? OFFSET ?"
            cursor.execute(query, params + [limit, offset])
            questionnaires = cursor.fetchall()
        
        result = []
        for q in questionnaires:
            # è§£ædataå­—æ®µè·å–è¯¦ç»†ä¿¡æ¯
            data = json.loads(q['data'])
            
            # ä»dataä¸­æå–æ€§åˆ«ã€å‡ºç”Ÿæ—¥æœŸã€å®¶é•¿è”ç³»ä¿¡æ¯ã€å­¦æ ¡å’Œè€å¸ˆä¿¡æ¯
            gender = None
            birthdate = None
            parent_phone = None
            parent_wechat = None
            parent_email = None
            school = None
            teacher = None
            
            # å°è¯•ä»ä¸åŒä½ç½®è·å–åŸºæœ¬ä¿¡æ¯
            if 'basicInfo' in data and data['basicInfo']:
                basic_info = data['basicInfo']
                gender = basic_info.get('gender')
                birthdate = basic_info.get('birthdate') or basic_info.get('birth_date')
                parent_phone = basic_info.get('parent_phone')
                parent_wechat = basic_info.get('parent_wechat')
                parent_email = basic_info.get('parent_email')
                school = basic_info.get('school')
                teacher = basic_info.get('teacher')
            elif 'basic_info' in data and data['basic_info']:
                basic_info = data['basic_info']
                gender = basic_info.get('gender')
                birthdate = basic_info.get('birthdate') or basic_info.get('birth_date')
                parent_phone = basic_info.get('parent_phone')
                parent_wechat = basic_info.get('parent_wechat')
                parent_email = basic_info.get('parent_email')
                school = basic_info.get('school')
                teacher = basic_info.get('teacher')
            
            # å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œå°è¯•ä»é¡¶çº§å­—æ®µè·å–
            if not gender:
                gender = data.get('gender') or data.get('basic_info_gender')
            if not birthdate:
                birthdate = data.get('birthdate') or data.get('basic_info_birthdate') or data.get('birth_date')
            if not parent_phone:
                parent_phone = data.get('parent_phone') or data.get('basic_info_parent_phone')
            if not parent_wechat:
                parent_wechat = data.get('parent_wechat') or data.get('basic_info_parent_wechat')
            if not parent_email:
                parent_email = data.get('parent_email') or data.get('basic_info_parent_email')
            if not school:
                school = data.get('school') or data.get('basic_info_school')
            if not teacher:
                teacher = data.get('teacher') or data.get('basic_info_teacher')
            
            result.append({
                'id': q['id'],
                'type': q['type'],
                'name': q['name'],
                'grade': q['grade'],
                'gender': gender,
                'birthdate': birthdate,
                'submission_date': q['submission_date'],
                'created_at': q['created_at'],
                'updated_at': q['updated_at'],
                'parent_phone': parent_phone,
                'parent_wechat': parent_wechat,
                'parent_email': parent_email,
                'school': school,
                'teacher': teacher,
                'school_name': q['school_name'],
                'admission_date': q['admission_date'],
                'address': q['address'],
                'filler_name': q['filler_name'],
                'fill_date': q['fill_date'],
                'data': data
            })
        
        # è®°å½•æŸ¥è¯¢æ“ä½œæ—¥å¿—ï¼ˆä»…åœ¨æœ‰æœç´¢æ¡ä»¶æ—¶ï¼‰
        if search or questionnaire_type or grade_filter or date_from or date_to:
            search_details = {
                'search': search,
                'type': questionnaire_type,
                'grade': grade_filter,
                'date_from': date_from,
                'date_to': date_to,
                'results_count': len(result)
            }
            OperationLogger.log('SEARCH_QUESTIONNAIRES', None, f'æœç´¢é—®å·: {json.dumps(search_details, default=str, ensure_ascii=False)}')
        
        return jsonify({
            'success': True,
            'data': result,
            'pagination': {
                'page': page,
                'limit': limit,
                'total': total_count,
                'pages': (total_count + limit - 1) // limit,
                'has_next': page < (total_count + limit - 1) // limit,
                'has_prev': page > 1
            },
            'filters': {
                'search': search,
                'type': questionnaire_type,
                'grade': grade_filter,
                'date_from': date_from,
                'date_to': date_to,
                'sort_by': sort_by,
                'sort_order': sort_order
            }
        })
    except Exception as e:
        response_data, status_code = server_error('è·å–é—®å·åˆ—è¡¨å¤±è´¥', str(e))
        return jsonify(response_data), status_code

# è·å–ç­›é€‰é€‰é¡¹ - ç”¨äºé«˜çº§æœç´¢
@app.route('/api/questionnaires/filters', methods=['GET'])
@login_required
def get_filter_options():
    """è·å–å¯ç”¨çš„ç­›é€‰é€‰é¡¹"""
    try:
        with get_db() as conn:
            cursor = conn.cursor()
            
            # è·å–æ‰€æœ‰å¯ç”¨çš„é—®å·ç±»å‹
            cursor.execute("SELECT DISTINCT type FROM questionnaires WHERE type IS NOT NULL ORDER BY type")
            types = [row[0] for row in cursor.fetchall()]
            
            # è·å–æ‰€æœ‰å¯ç”¨çš„å¹´çº§
            cursor.execute("SELECT DISTINCT grade FROM questionnaires WHERE grade IS NOT NULL AND grade != '' ORDER BY grade")
            grades = [row[0] for row in cursor.fetchall()]
            
            # è·å–æ—¥æœŸèŒƒå›´
            cursor.execute("SELECT MIN(DATE(created_at)), MAX(DATE(created_at)) FROM questionnaires")
            date_range = cursor.fetchone()
            
            return jsonify({
                'success': True,
                'data': {
                    'types': types,
                    'grades': grades,
                    'date_range': {
                        'min': date_range[0],
                        'max': date_range[1]
                    },
                    'sort_options': [
                        {'value': 'created_at', 'label': 'åˆ›å»ºæ—¶é—´'},
                        {'value': 'updated_at', 'label': 'æ›´æ–°æ—¶é—´'},
                        {'value': 'name', 'label': 'å§“å'},
                        {'value': 'type', 'label': 'é—®å·ç±»å‹'},
                        {'value': 'grade', 'label': 'å¹´çº§'},
                        {'value': 'submission_date', 'label': 'æäº¤æ—¥æœŸ'}
                    ]
                }
            })
    except Exception as e:
        response_data, status_code = server_error('è·å–ç­›é€‰é€‰é¡¹å¤±è´¥', str(e))
        return jsonify(response_data), status_code

# è·å–å•ä¸ªé—®å·æ•°æ®
@app.route('/api/questionnaires/<int:questionnaire_id>', methods=['GET'])
@login_required
def get_questionnaire(questionnaire_id):
    try:
        with get_db() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM questionnaires WHERE id = ?", (questionnaire_id,))
            q = cursor.fetchone()
        
        if not q:
            response_data, status_code = not_found_error('é—®å·')
            return jsonify(response_data), status_code
        
        result = {
            'success': True,
            'data': {
                'id': q['id'],
                'type': q['type'],
                'name': q['name'],
                'grade': q['grade'],
                'submission_date': q['submission_date'],
                'created_at': q['created_at'],
                'updated_at': q['updated_at'],
                'data': json.loads(q['data'])
            }
        }
        
        return jsonify(result)
    except Exception as e:
        response_data, status_code = server_error('è·å–é—®å·è¯¦æƒ…å¤±è´¥', str(e))
        return jsonify(response_data), status_code

# æ›´æ–°é—®å·æ•°æ®
@app.route('/api/questionnaires/<int:questionnaire_id>', methods=['PUT'])
@admin_required
def update_questionnaire(questionnaire_id):
    try:
        data = request.json
        print(f"[DEBUG] æ¥æ”¶åˆ°çš„åŸå§‹æ•°æ®: {json.dumps(data, ensure_ascii=False, indent=2)}")
        
        if not data:
            error_msg = 'è¯·æ±‚æ•°æ®ä¸èƒ½ä¸ºç©º'
            print(f"[ERROR] {error_msg}")
            return jsonify(create_validation_error_response([error_msg])), 400
        
        # è·å–åŸå§‹é—®å·æ•°æ®
        with get_db() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT data, type, name, grade, submission_date FROM questionnaires WHERE id = ?", (questionnaire_id,))
            result = cursor.fetchone()
            
            if not result:
                return jsonify({
                    'success': False,
                    'error': {
                        'code': 'NOT_FOUND',
                        'message': 'é—®å·ä¸å­˜åœ¨'
                    }
                }), 404
            
            original_data_str, original_type, original_name, original_grade, original_submission_date = result
            original_data = json.loads(original_data_str) if original_data_str else {}
        
        # å¢é‡æ›´æ–°ï¼šåˆå¹¶åŸå§‹æ•°æ®å’Œæ–°æ•°æ®
        merged_data = merge_questionnaire_data(original_data, data)
        print(f"[DEBUG] åˆå¹¶åçš„æ•°æ®: {json.dumps(merged_data, ensure_ascii=False, indent=2)}")
        
        # æ•°æ®æ ‡å‡†åŒ–
        try:
            normalized_data = normalize_questionnaire_data(merged_data)
            print(f"[DEBUG] æ ‡å‡†åŒ–åçš„æ•°æ®: {json.dumps(normalized_data, ensure_ascii=False, indent=2)}")
        except Exception as e:
            error_msg = f'æ•°æ®æ ‡å‡†åŒ–å¤±è´¥: {str(e)}'
            print(f"[ERROR] {error_msg}")
            return jsonify(create_validation_error_response([error_msg])), 400
        
        # ä½¿ç”¨æ–°çš„éªŒè¯æ¨¡å—è¿›è¡ŒéªŒè¯
        is_valid, validation_errors, validated_data = validate_questionnaire_with_schema(normalized_data)
        
        if not is_valid:
            error_msg = f'æ•°æ®éªŒè¯å¤±è´¥: {validation_errors}'
            print(f"[ERROR] {error_msg}")
            return jsonify(create_validation_error_response(validation_errors)), 400
        
        # ä»éªŒè¯åçš„æ•°æ®ä¸­æå–åŸºæœ¬ä¿¡æ¯
        questionnaire_type = validated_data.get('type', original_type)
        basic_info = validated_data.get('basic_info', {})
        name = basic_info.get('name', original_name)
        grade = basic_info.get('grade', original_grade)
        submission_date = basic_info.get('submission_date', original_submission_date)
        
        updated_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # ä½¿ç”¨é—®é¢˜ç±»å‹å¤„ç†å™¨è¿›è¡Œæœ€ç»ˆå¤„ç†
        final_data = process_complete_questionnaire(validated_data)
        
        with get_db() as conn:
            cursor = conn.cursor()
            cursor.execute(
                "UPDATE questionnaires SET type = ?, name = ?, grade = ?, submission_date = ?, updated_at = ?, data = ? WHERE id = ?",
                (questionnaire_type, name, grade, submission_date, updated_at, json.dumps(final_data, default=str, ensure_ascii=False), questionnaire_id)
            )
            conn.commit()
        
        # è®°å½•æ“ä½œæ—¥å¿—
        OperationLogger.log(OperationLogger.UPDATE_QUESTIONNAIRE, questionnaire_id, f'å¢é‡æ›´æ–°é—®å·: {name} - {questionnaire_type}')
        
        return jsonify({
            'success': True,
            'message': 'é—®å·æ›´æ–°æˆåŠŸ',
            'timestamp': datetime.now().isoformat()
        })
    except ValidationError as e:
        return jsonify(create_validation_error_response(e.messages)), 400
    except Exception as e:
        return jsonify({
            'success': False,
            'error': {
                'code': 'SERVER_ERROR',
                'message': 'æ›´æ–°é—®å·å¤±è´¥',
                'details': str(e)
            }
        }), 500

# æ‰¹é‡åˆ é™¤é—®å·
@app.route('/api/questionnaires/batch', methods=['DELETE'])
@admin_required
def batch_delete_questionnaires():
    try:
        data = request.json
        questionnaire_ids = data.get('ids', [])
        
        if not questionnaire_ids:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'VALIDATION_ERROR',
                    'message': 'æœªæä¾›é—®å·ID'
                }
            }), 400
        
        # éªŒè¯å¹¶è½¬æ¢IDæ ¼å¼
        try:
            # å°è¯•å°†æ‰€æœ‰IDè½¬æ¢ä¸ºæ•´æ•°
            questionnaire_ids = [int(id) for id in questionnaire_ids]
            # éªŒè¯è½¬æ¢åçš„IDæ˜¯å¦æœ‰æ•ˆ
            if not all(id > 0 for id in questionnaire_ids):
                return jsonify({
                    'success': False,
                    'error': {
                        'code': 'VALIDATION_ERROR',
                        'message': 'é—®å·IDå¿…é¡»ä¸ºæ­£æ•´æ•°'
                    }
                }), 400
        except (ValueError, TypeError):
            return jsonify({
                'success': False,
                'error': {
                    'code': 'VALIDATION_ERROR',
                    'message': 'é—®å·IDæ ¼å¼æ— æ•ˆ'
                }
            }), 400
        
        with get_db() as conn:
            cursor = conn.cursor()
            
            # é¦–å…ˆæ£€æŸ¥è¦åˆ é™¤çš„é—®å·æ˜¯å¦å­˜åœ¨
            placeholders = ','.join(['?'] * len(questionnaire_ids))
            cursor.execute(f"SELECT id, name, type FROM questionnaires WHERE id IN ({placeholders})", questionnaire_ids)
            existing_questionnaires = cursor.fetchall()
            
            if not existing_questionnaires:
                return jsonify({
                    'success': False,
                    'error': {
                        'code': 'NOT_FOUND',
                        'message': 'æœªæ‰¾åˆ°æŒ‡å®šçš„é—®å·'
                    }
                }), 404
            
            # æ‰§è¡Œæ‰¹é‡åˆ é™¤
            cursor.execute(f"DELETE FROM questionnaires WHERE id IN ({placeholders})", questionnaire_ids)
            conn.commit()
            
            deleted_count = cursor.rowcount
            
            # é‡æ–°æ’åºID
            cursor.execute("SELECT id FROM questionnaires ORDER BY created_at")
            questionnaires = cursor.fetchall()
            
            for new_id, questionnaire in enumerate(questionnaires, 1):
                old_id = questionnaire['id']
                if old_id != new_id:
                    cursor.execute("UPDATE questionnaires SET id = ? WHERE id = ?", (new_id, old_id))
            
            conn.commit()
            
            # é‡ç½®è‡ªå¢è®¡æ•°å™¨
            cursor.execute("UPDATE sqlite_sequence SET seq = (SELECT COUNT(*) FROM questionnaires) WHERE name = 'questionnaires'")
            conn.commit()
        
        # è®°å½•æ“ä½œæ—¥å¿—
        questionnaire_names = [q['name'] for q in existing_questionnaires]
        OperationLogger.log(OperationLogger.BATCH_DELETE, None, f'æ‰¹é‡åˆ é™¤é—®å· {deleted_count} æ¡: {", ".join(questionnaire_names)}')
        
        return jsonify({
            'success': True,
            'message': f'æˆåŠŸåˆ é™¤ {deleted_count} æ¡é—®å·',
            'deleted_count': deleted_count,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': {
                'code': 'SERVER_ERROR',
                'message': 'æ‰¹é‡åˆ é™¤å¤±è´¥',
                'details': str(e)
            }
        }), 500

# åˆ é™¤é—®å·
@app.route('/api/questionnaires/<int:questionnaire_id>', methods=['DELETE'])
@admin_required
def delete_questionnaire(questionnaire_id):
    """åˆ é™¤æŒ‡å®šé—®å·"""
    try:
        with get_db() as conn:
            cursor = conn.cursor()
            
            # é¦–å…ˆè·å–è¦åˆ é™¤çš„é—®å·ä¿¡æ¯ç”¨äºæ—¥å¿—è®°å½•
            cursor.execute("SELECT name, type, data FROM questionnaires WHERE id = ?", (questionnaire_id,))
            questionnaire_row = cursor.fetchone()
            
            if not questionnaire_row:
                response_data, status_code = not_found_error('é—®å·ä¸å­˜åœ¨')
                return jsonify(response_data), status_code
            
            # æå–é—®å·ä¿¡æ¯
            questionnaire_name = questionnaire_row['name'] or 'æœªçŸ¥'
            questionnaire_type = questionnaire_row['type'] or 'æœªçŸ¥'
            
            # æ‰§è¡Œåˆ é™¤
            cursor.execute("DELETE FROM questionnaires WHERE id = ?", (questionnaire_id,))
            deleted_count = cursor.rowcount
            
            if deleted_count == 0:
                response_data, status_code = not_found_error('é—®å·ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤')
                return jsonify(response_data), status_code
            
            # é‡æ–°æ’åºID - ä¿æŒè¿ç»­æ€§
            cursor.execute("SELECT id FROM questionnaires ORDER BY created_at")
            questionnaires = cursor.fetchall()
            
            for new_id, questionnaire in enumerate(questionnaires, 1):
                old_id = questionnaire['id']
                if old_id != new_id:
                    cursor.execute("UPDATE questionnaires SET id = ? WHERE id = ?", (new_id, old_id))
            
            conn.commit()
            
            # é‡ç½®è‡ªå¢è®¡æ•°å™¨
            cursor.execute("UPDATE sqlite_sequence SET seq = (SELECT COUNT(*) FROM questionnaires) WHERE name = 'questionnaires'")
            conn.commit()
        
        # è®°å½•æ“ä½œæ—¥å¿—
        OperationLogger.log(OperationLogger.DELETE_QUESTIONNAIRE, questionnaire_id, 
                     f'åˆ é™¤é—®å·: {questionnaire_name} - {questionnaire_type}')
        
        return jsonify({
            'success': True,
            'message': 'é—®å·åˆ é™¤æˆåŠŸï¼Œæ•°æ®å·²é‡æ–°ç¼–å·',
            'deleted_id': questionnaire_id,
            'reindexed': True,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        response_data, status_code = server_error('åˆ é™¤é—®å·å¤±è´¥', str(e))
        return jsonify(response_data), status_code

# ==================== ç³»ç»Ÿç›‘æ§å’Œç»Ÿè®¡åŠŸèƒ½ ====================

@app.route('/api/admin/statistics', methods=['GET'])
@login_required
def get_admin_statistics():
    """è·å–ç®¡ç†ç»Ÿè®¡æ•°æ® - å¢å¼ºç‰ˆæœ¬"""
    try:
        with get_db() as conn:
            cursor = conn.cursor()
            
            # åŸºç¡€ç»Ÿè®¡æ•°æ®
            cursor.execute("SELECT COUNT(*) FROM questionnaires")
            total_count = cursor.fetchone()[0]
            
            # ä»Šæ—¥æ–°å¢é—®å·æ•°
            today = datetime.now().strftime('%Y-%m-%d')
            cursor.execute("SELECT COUNT(*) FROM questionnaires WHERE DATE(created_at) = ?", (today,))
            today_count = cursor.fetchone()[0]
            
            # æœ¬å‘¨æ–°å¢é—®å·æ•°
            cursor.execute("SELECT COUNT(*) FROM questionnaires WHERE DATE(created_at) >= DATE('now', '-7 days')")
            week_count = cursor.fetchone()[0]
            
            # æœ¬æœˆæ–°å¢é—®å·æ•°
            cursor.execute("SELECT COUNT(*) FROM questionnaires WHERE DATE(created_at) >= DATE('now', 'start of month')")
            month_count = cursor.fetchone()[0]
            
            # æŒ‰ç±»å‹åˆ†ç»„çš„ç»Ÿè®¡
            cursor.execute("SELECT type, COUNT(*) FROM questionnaires GROUP BY type")
            type_stats = dict(cursor.fetchall())
            
            # æŒ‰å¹´çº§åˆ†ç»„çš„ç»Ÿè®¡
            cursor.execute("SELECT grade, COUNT(*) FROM questionnaires WHERE grade IS NOT NULL GROUP BY grade")
            grade_stats = dict(cursor.fetchall())
            
            # æœ€è¿‘30å¤©çš„æäº¤è¶‹åŠ¿
            cursor.execute("""
                SELECT DATE(created_at) as date, COUNT(*) as count 
                FROM questionnaires 
                WHERE DATE(created_at) >= DATE('now', '-30 days')
                GROUP BY DATE(created_at)
                ORDER BY date
            """)
            trend_data = [{'date': row[0], 'count': row[1]} for row in cursor.fetchall()]
            
            # æ¯å°æ—¶æäº¤åˆ†å¸ƒï¼ˆä»Šæ—¥ï¼‰
            cursor.execute("""
                SELECT strftime('%H', created_at) as hour, COUNT(*) as count
                FROM questionnaires 
                WHERE DATE(created_at) = ?
                GROUP BY strftime('%H', created_at)
                ORDER BY hour
            """, (today,))
            hourly_stats = [{'hour': int(row[0]), 'count': row[1]} for row in cursor.fetchall()]
            
            # ç”¨æˆ·æ´»åŠ¨ç»Ÿè®¡
            cursor.execute("SELECT COUNT(*) FROM users")
            total_users = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM users WHERE DATE(last_login) = ?", (today,))
            active_users_today = cursor.fetchone()[0]
            
            # æ“ä½œæ—¥å¿—ç»Ÿè®¡
            cursor.execute("SELECT COUNT(*) FROM operation_logs")
            total_operations = cursor.fetchone()[0]
            
            cursor.execute("SELECT COUNT(*) FROM operation_logs WHERE DATE(created_at) = ?", (today,))
            operations_today = cursor.fetchone()[0]
            
            # æ•°æ®åº“å¤§å°ç»Ÿè®¡
            cursor.execute("SELECT page_count * page_size as size FROM pragma_page_count(), pragma_page_size()")
            db_size = cursor.fetchone()[0] if cursor.fetchone() else 0
            
        return jsonify({
            'success': True,
            'data': {
                'overview': {
                    'total_questionnaires': total_count,
                    'today_submissions': today_count,
                    'week_submissions': week_count,
                    'month_submissions': month_count,
                    'total_users': total_users,
                    'active_users_today': active_users_today,
                    'total_operations': total_operations,
                    'operations_today': operations_today,
                    'database_size': db_size
                },
                'distributions': {
                    'type_distribution': type_stats,
                    'grade_distribution': grade_stats
                },
                'trends': {
                    'submission_trend': trend_data,
                    'hourly_distribution': hourly_stats
                }
            },
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': {
                'code': 'SERVER_ERROR',
                'message': 'è·å–ç»Ÿè®¡æ•°æ®å¤±è´¥',
                'details': str(e)
            }
        }), 500

@app.route('/api/admin/system/health', methods=['GET'])
@login_required
def system_health_check():
    """ç³»ç»Ÿå¥åº·æ£€æŸ¥æ¥å£"""
    try:
        health_status = {
            'status': 'healthy',
            'checks': {},
            'timestamp': datetime.now().isoformat()
        }
        
        # æ•°æ®åº“è¿æ¥æ£€æŸ¥
        try:
            with get_db() as conn:
                cursor = conn.cursor()
                cursor.execute("SELECT 1")
                cursor.fetchone()
            health_status['checks']['database'] = {
                'status': 'healthy',
                'message': 'æ•°æ®åº“è¿æ¥æ­£å¸¸'
            }
        except Exception as e:
            health_status['checks']['database'] = {
                'status': 'unhealthy',
                'message': f'æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}'
            }
            health_status['status'] = 'unhealthy'
        
        # ç£ç›˜ç©ºé—´æ£€æŸ¥
        try:
            import shutil
            total, used, free = shutil.disk_usage(os.path.dirname(DATABASE))
            free_percent = (free / total) * 100
            
            if free_percent > 10:
                health_status['checks']['disk_space'] = {
                    'status': 'healthy',
                    'message': f'ç£ç›˜ç©ºé—´å……è¶³ ({free_percent:.1f}% å¯ç”¨)',
                    'free_space_gb': free // (1024**3),
                    'free_percent': round(free_percent, 1)
                }
            else:
                health_status['checks']['disk_space'] = {
                    'status': 'warning',
                    'message': f'ç£ç›˜ç©ºé—´ä¸è¶³ ({free_percent:.1f}% å¯ç”¨)',
                    'free_space_gb': free // (1024**3),
                    'free_percent': round(free_percent, 1)
                }
                if health_status['status'] == 'healthy':
                    health_status['status'] = 'warning'
        except Exception as e:
            health_status['checks']['disk_space'] = {
                'status': 'unknown',
                'message': f'æ— æ³•æ£€æŸ¥ç£ç›˜ç©ºé—´: {str(e)}'
            }
        
        # å†…å­˜ä½¿ç”¨æ£€æŸ¥
        try:
            import psutil
            memory = psutil.virtual_memory()
            memory_percent = memory.percent
            
            if memory_percent < 80:
                health_status['checks']['memory'] = {
                    'status': 'healthy',
                    'message': f'å†…å­˜ä½¿ç”¨æ­£å¸¸ ({memory_percent:.1f}%)',
                    'memory_percent': round(memory_percent, 1),
                    'available_gb': round(memory.available / (1024**3), 1)
                }
            elif memory_percent < 90:
                health_status['checks']['memory'] = {
                    'status': 'warning',
                    'message': f'å†…å­˜ä½¿ç”¨è¾ƒé«˜ ({memory_percent:.1f}%)',
                    'memory_percent': round(memory_percent, 1),
                    'available_gb': round(memory.available / (1024**3), 1)
                }
                if health_status['status'] == 'healthy':
                    health_status['status'] = 'warning'
            else:
                health_status['checks']['memory'] = {
                    'status': 'critical',
                    'message': f'å†…å­˜ä½¿ç”¨è¿‡é«˜ ({memory_percent:.1f}%)',
                    'memory_percent': round(memory_percent, 1),
                    'available_gb': round(memory.available / (1024**3), 1)
                }
                health_status['status'] = 'critical'
        except ImportError:
            health_status['checks']['memory'] = {
                'status': 'unknown',
                'message': 'éœ€è¦å®‰è£… psutil åº“æ¥æ£€æŸ¥å†…å­˜ä½¿ç”¨'
            }
        except Exception as e:
            health_status['checks']['memory'] = {
                'status': 'unknown',
                'message': f'æ— æ³•æ£€æŸ¥å†…å­˜ä½¿ç”¨: {str(e)}'
            }
        
        # ä¼šè¯å­˜å‚¨æ£€æŸ¥
        try:
            session_count = len([k for k in session.keys() if not k.startswith('_')])
            health_status['checks']['sessions'] = {
                'status': 'healthy',
                'message': f'ä¼šè¯ç³»ç»Ÿæ­£å¸¸ (å½“å‰ä¼šè¯é¡¹: {session_count})',
                'session_items': session_count
            }
        except Exception as e:
            health_status['checks']['sessions'] = {
                'status': 'warning',
                'message': f'ä¼šè¯ç³»ç»Ÿå¼‚å¸¸: {str(e)}'
            }
            if health_status['status'] == 'healthy':
                health_status['status'] = 'warning'
        
        return jsonify({
            'success': True,
            'data': health_status
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': {
                'code': 'SERVER_ERROR',
                'message': 'ç³»ç»Ÿå¥åº·æ£€æŸ¥å¤±è´¥',
                'details': str(e)
            }
        }), 500

@app.route('/api/admin/system/performance', methods=['GET'])
@login_required
def system_performance_metrics():
    """ç³»ç»Ÿæ€§èƒ½ç›‘æ§æŒ‡æ ‡"""
    try:
        metrics = {
            'timestamp': datetime.now().isoformat(),
            'uptime': time.time() - app.config.get('START_TIME', time.time()),
            'metrics': {}
        }
        
        # æ•°æ®åº“æ€§èƒ½æŒ‡æ ‡
        try:
            with get_db() as conn:
                cursor = conn.cursor()
                
                # æ•°æ®åº“å¤§å°
                cursor.execute("SELECT page_count * page_size as size FROM pragma_page_count(), pragma_page_size()")
                db_size_result = cursor.fetchone()
                db_size = db_size_result[0] if db_size_result else 0
                
                # è¡¨ç»Ÿè®¡
                cursor.execute("SELECT COUNT(*) FROM questionnaires")
                questionnaire_count = cursor.fetchone()[0]
                
                cursor.execute("SELECT COUNT(*) FROM operation_logs")
                log_count = cursor.fetchone()[0]
                
                cursor.execute("SELECT COUNT(*) FROM users")
                user_count = cursor.fetchone()[0]
                
                # æœ€è¿‘çš„æ“ä½œé¢‘ç‡
                cursor.execute("""
                    SELECT COUNT(*) FROM operation_logs 
                    WHERE created_at >= datetime('now', '-1 hour')
                """)
                operations_last_hour = cursor.fetchone()[0]
                
                metrics['metrics']['database'] = {
                    'size_bytes': db_size,
                    'size_mb': round(db_size / (1024*1024), 2),
                    'questionnaire_count': questionnaire_count,
                    'log_count': log_count,
                    'user_count': user_count,
                    'operations_last_hour': operations_last_hour
                }
        except Exception as e:
            metrics['metrics']['database'] = {
                'error': f'æ•°æ®åº“æŒ‡æ ‡è·å–å¤±è´¥: {str(e)}'
            }
        
        # ç³»ç»Ÿèµ„æºæŒ‡æ ‡
        try:
            import psutil
            
            # CPU ä½¿ç”¨ç‡
            cpu_percent = psutil.cpu_percent(interval=1)
            
            # å†…å­˜ä½¿ç”¨
            memory = psutil.virtual_memory()
            
            # ç£ç›˜ä½¿ç”¨
            disk = psutil.disk_usage(os.path.dirname(DATABASE))
            
            metrics['metrics']['system'] = {
                'cpu_percent': round(cpu_percent, 1),
                'memory': {
                    'total_gb': round(memory.total / (1024**3), 2),
                    'available_gb': round(memory.available / (1024**3), 2),
                    'percent': round(memory.percent, 1)
                },
                'disk': {
                    'total_gb': round(disk.total / (1024**3), 2),
                    'free_gb': round(disk.free / (1024**3), 2),
                    'percent': round((disk.used / disk.total) * 100, 1)
                }
            }
        except ImportError:
            metrics['metrics']['system'] = {
                'error': 'éœ€è¦å®‰è£… psutil åº“æ¥è·å–ç³»ç»ŸæŒ‡æ ‡'
            }
        except Exception as e:
            metrics['metrics']['system'] = {
                'error': f'ç³»ç»ŸæŒ‡æ ‡è·å–å¤±è´¥: {str(e)}'
            }
        
        # åº”ç”¨ç¨‹åºæŒ‡æ ‡
        try:
            # æ´»è·ƒä¼šè¯æ•°ï¼ˆç®€åŒ–ç»Ÿè®¡ï¼‰
            active_sessions = 1 if 'user_id' in session else 0
            
            # æœ€è¿‘é”™è¯¯ç»Ÿè®¡
            with get_db() as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT COUNT(*) FROM operation_logs 
                    WHERE operation LIKE '%ERROR%' 
                    AND created_at >= datetime('now', '-24 hours')
                """)
                errors_24h = cursor.fetchone()[0]
            
            metrics['metrics']['application'] = {
                'active_sessions': active_sessions,
                'errors_24h': errors_24h,
                'flask_env': app.config.get('ENV', 'unknown'),
                'debug_mode': app.debug
            }
        except Exception as e:
            metrics['metrics']['application'] = {
                'error': f'åº”ç”¨æŒ‡æ ‡è·å–å¤±è´¥: {str(e)}'
            }
        
        return jsonify({
            'success': True,
            'data': metrics
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': {
                'code': 'SERVER_ERROR',
                'message': 'è·å–æ€§èƒ½æŒ‡æ ‡å¤±è´¥',
                'details': str(e)
            }
        }), 500

@app.route('/api/admin/system/realtime', methods=['GET'])
@login_required
def realtime_statistics():
    """å®æ—¶ç»Ÿè®¡æ•°æ®æ¥å£"""
    try:
        with get_db() as conn:
            cursor = conn.cursor()
            
            # æœ€è¿‘1å°æ—¶çš„æ´»åŠ¨
            cursor.execute("""
                SELECT COUNT(*) FROM questionnaires 
                WHERE created_at >= datetime('now', '-1 hour')
            """)
            submissions_last_hour = cursor.fetchone()[0]
            
            # æœ€è¿‘1å°æ—¶çš„æ“ä½œ
            cursor.execute("""
                SELECT COUNT(*) FROM operation_logs 
                WHERE created_at >= datetime('now', '-1 hour')
            """)
            operations_last_hour = cursor.fetchone()[0]
            
            # æœ€è¿‘5åˆ†é’Ÿçš„æ´»åŠ¨
            cursor.execute("""
                SELECT COUNT(*) FROM questionnaires 
                WHERE created_at >= datetime('now', '-5 minutes')
            """)
            submissions_last_5min = cursor.fetchone()[0]
            
            # æœ€è¿‘çš„æäº¤è®°å½•
            cursor.execute("""
                SELECT id, name, type, created_at 
                FROM questionnaires 
                ORDER BY created_at DESC 
                LIMIT 5
            """)
            recent_submissions = [
                {
                    'id': row[0],
                    'name': row[1],
                    'type': row[2],
                    'created_at': row[3]
                }
                for row in cursor.fetchall()
            ]
            
            # æœ€è¿‘çš„æ“ä½œæ—¥å¿—
            cursor.execute("""
                SELECT operation, created_at, details 
                FROM operation_logs 
                ORDER BY created_at DESC 
                LIMIT 5
            """)
            recent_operations = [
                {
                    'operation': row[0],
                    'created_at': row[1],
                    'details': json.loads(row[2]) if row[2] else {}
                }
                for row in cursor.fetchall()
            ]
        
        return jsonify({
            'success': True,
            'data': {
                'activity': {
                    'submissions_last_hour': submissions_last_hour,
                    'operations_last_hour': operations_last_hour,
                    'submissions_last_5min': submissions_last_5min
                },
                'recent': {
                    'submissions': recent_submissions,
                    'operations': recent_operations
                },
                'timestamp': datetime.now().isoformat()
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': {
                'code': 'SERVER_ERROR',
                'message': 'è·å–å®æ—¶ç»Ÿè®¡å¤±è´¥',
                'details': str(e)
            }
        }), 500

# è·å–æ“ä½œæ—¥å¿—
@app.route('/api/admin/logs', methods=['GET'])
@admin_required
def get_operation_logs():
    try:
        # è·å–æŸ¥è¯¢å‚æ•°
        page = int(request.args.get('page', 1))
        limit = int(request.args.get('limit', 50))
        operation_type = request.args.get('operation', '').strip()
        user_filter = request.args.get('user', '').strip()
        date_from = request.args.get('date_from', '').strip()
        date_to = request.args.get('date_to', '').strip()
        sensitive_only = request.args.get('sensitive_only', '').lower() == 'true'
        
        # é™åˆ¶æ¯é¡µæœ€å¤§æ•°é‡
        limit = min(limit, 200)
        
        with get_db() as conn:
            cursor = conn.cursor()
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            where_conditions = []
            params = []
            
            if operation_type:
                where_conditions.append("ol.operation LIKE ?")
                params.append(f"%{operation_type}%")
            
            if user_filter:
                where_conditions.append("u.username LIKE ?")
                params.append(f"%{user_filter}%")
            
            if date_from:
                where_conditions.append("DATE(ol.created_at) >= ?")
                params.append(date_from)
            
            if date_to:
                where_conditions.append("DATE(ol.created_at) <= ?")
                params.append(date_to)
            
            if sensitive_only:
                sensitive_ops = "', '".join(OperationLogger.SENSITIVE_OPERATIONS)
                where_conditions.append(f"ol.operation IN ('{sensitive_ops}')")
            
            where_clause = ""
            if where_conditions:
                where_clause = "WHERE " + " AND ".join(where_conditions)
            
            # è·å–æ€»æ•°
            count_query = f"""
                SELECT COUNT(*) 
                FROM operation_logs ol
                LEFT JOIN users u ON ol.user_id = u.id
                {where_clause}
            """
            cursor.execute(count_query, params)
            total_count = cursor.fetchone()[0]
            
            # è·å–åˆ†é¡µæ•°æ®
            offset = (page - 1) * limit
            query = f"""
                SELECT ol.*, u.username 
                FROM operation_logs ol
                LEFT JOIN users u ON ol.user_id = u.id
                {where_clause}
                ORDER BY ol.created_at DESC
                LIMIT ? OFFSET ?
            """
            cursor.execute(query, params + [limit, offset])
            logs = cursor.fetchall()
        
        result = []
        for log in logs:
            # è§£æè¯¦ç»†ä¿¡æ¯
            details_data = {}
            try:
                if log['details']:
                    details_data = json.loads(log['details'])
            except:
                details_data = {'user_details': log['details']}
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºæ•æ„Ÿæ“ä½œ
            is_sensitive = log['operation'] in OperationLogger.SENSITIVE_OPERATIONS
            
            log_entry = {
                'id': log['id'],
                'user_id': log['user_id'],
                'username': log['username'] or 'System',
                'operation': log['operation'],
                'target_id': log['target_id'],
                'created_at': log['created_at'],
                'is_sensitive': is_sensitive,
                'ip_address': details_data.get('ip_address', 'unknown'),
                'user_agent': details_data.get('user_agent', 'unknown')[:100] + '...' if len(details_data.get('user_agent', '')) > 100 else details_data.get('user_agent', 'unknown'),
                'request_path': details_data.get('request_path', 'unknown'),
                'request_method': details_data.get('request_method', 'unknown'),
                'user_details': details_data.get('user_details', ''),
                'raw_details': log['details']  # ä¿ç•™åŸå§‹è¯¦æƒ…ç”¨äºè¯¦ç»†æŸ¥çœ‹
            }
            
            result.append(log_entry)
        
        # è®°å½•æ—¥å¿—æŸ¥çœ‹æ“ä½œ
        OperationLogger.log('VIEW_LOGS', None, f'æŸ¥çœ‹æ“ä½œæ—¥å¿—ï¼Œé¡µé¢: {page}, è¿‡æ»¤æ¡ä»¶: {request.args}')
        
        return jsonify({
            'success': True,
            'data': result,
            'pagination': {
                'page': page,
                'limit': limit,
                'total': total_count,
                'pages': (total_count + limit - 1) // limit
            },
            'filters': {
                'operation_type': operation_type,
                'user_filter': user_filter,
                'date_from': date_from,
                'date_to': date_to,
                'sensitive_only': sensitive_only
            }
        })
        
    except Exception as e:
        OperationLogger.log('SYSTEM_ERROR', None, f'è·å–æ“ä½œæ—¥å¿—å¤±è´¥: {str(e)}')
        return jsonify({
            'success': False,
            'error': {
                'code': 'SERVER_ERROR',
                'message': 'è·å–æ“ä½œæ—¥å¿—å¤±è´¥',
                'details': str(e)
            }
        }), 500

@app.route('/api/admin/logs/<int:log_id>', methods=['GET'])
@admin_required
def get_log_detail(log_id):
    """è·å–å•ä¸ªæ—¥å¿—è¯¦æƒ…"""
    try:
        with get_db() as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT ol.*, u.username 
                FROM operation_logs ol
                LEFT JOIN users u ON ol.user_id = u.id
                WHERE ol.id = ?
            """, (log_id,))
            log = cursor.fetchone()
        
        if not log:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'NOT_FOUND',
                    'message': 'æ—¥å¿—è®°å½•ä¸å­˜åœ¨'
                }
            }), 404
        
        # è§£æè¯¦ç»†ä¿¡æ¯
        details_data = {}
        try:
            if log['details']:
                details_data = json.loads(log['details'])
        except:
            details_data = {'user_details': log['details']}
        
        result = {
            'id': log['id'],
            'user_id': log['user_id'],
            'username': log['username'] or 'System',
            'operation': log['operation'],
            'target_id': log['target_id'],
            'created_at': log['created_at'],
            'is_sensitive': log['operation'] in OperationLogger.SENSITIVE_OPERATIONS,
            'details': details_data
        }
        
        # è®°å½•æŸ¥çœ‹æ—¥å¿—è¯¦æƒ…çš„æ“ä½œ
        OperationLogger.log('VIEW_LOG_DETAIL', log_id, f'æŸ¥çœ‹æ—¥å¿—è¯¦æƒ…: {log["operation"]}')
        
        return jsonify({
            'success': True,
            'data': result
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': {
                'code': 'SERVER_ERROR',
                'message': 'è·å–æ—¥å¿—è¯¦æƒ…å¤±è´¥',
                'details': str(e)
            }
        }), 500

@app.route('/api/admin/logs/statistics', methods=['GET'])
@admin_required
def get_log_statistics():
    """è·å–æ—¥å¿—ç»Ÿè®¡ä¿¡æ¯"""
    try:
        with get_db() as conn:
            cursor = conn.cursor()
            
            # æ€»æ—¥å¿—æ•°
            cursor.execute("SELECT COUNT(*) FROM operation_logs")
            total_logs = cursor.fetchone()[0]
            
            # ä»Šæ—¥æ—¥å¿—æ•°
            today = datetime.now().strftime('%Y-%m-%d')
            cursor.execute("SELECT COUNT(*) FROM operation_logs WHERE DATE(created_at) = ?", (today,))
            today_logs = cursor.fetchone()[0]
            
            # æ•æ„Ÿæ“ä½œæ•°
            sensitive_ops = "', '".join(OperationLogger.SENSITIVE_OPERATIONS)
            cursor.execute(f"SELECT COUNT(*) FROM operation_logs WHERE operation IN ('{sensitive_ops}')")
            sensitive_logs = cursor.fetchone()[0]
            
            # æŒ‰æ“ä½œç±»å‹ç»Ÿè®¡
            cursor.execute("""
                SELECT operation, COUNT(*) as count 
                FROM operation_logs 
                GROUP BY operation 
                ORDER BY count DESC 
                LIMIT 10
            """)
            operation_stats = [{'operation': row[0], 'count': row[1]} for row in cursor.fetchall()]
            
            # æŒ‰ç”¨æˆ·ç»Ÿè®¡
            cursor.execute("""
                SELECT u.username, COUNT(*) as count 
                FROM operation_logs ol
                LEFT JOIN users u ON ol.user_id = u.id
                WHERE u.username IS NOT NULL
                GROUP BY u.username 
                ORDER BY count DESC 
                LIMIT 10
            """)
            user_stats = [{'username': row[0], 'count': row[1]} for row in cursor.fetchall()]
            
            # æœ€è¿‘7å¤©çš„æ´»åŠ¨è¶‹åŠ¿
            cursor.execute("""
                SELECT DATE(created_at) as date, COUNT(*) as count 
                FROM operation_logs 
                WHERE DATE(created_at) >= DATE('now', '-7 days')
                GROUP BY DATE(created_at)
                ORDER BY date
            """)
            activity_trend = [{'date': row[0], 'count': row[1]} for row in cursor.fetchall()]
        
        return jsonify({
            'success': True,
            'data': {
                'total_logs': total_logs,
                'today_logs': today_logs,
                'sensitive_logs': sensitive_logs,
                'operation_statistics': operation_stats,
                'user_statistics': user_stats,
                'activity_trend': activity_trend
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': {
                'code': 'SERVER_ERROR',
                'message': 'è·å–æ—¥å¿—ç»Ÿè®¡å¤±è´¥',
                'details': str(e)
            }
        }), 500

@app.route('/api/admin/logs/export', methods=['POST'])
@admin_required
def export_logs():
    """å¯¼å‡ºæ“ä½œæ—¥å¿—"""
    try:
        data = request.json or {}
        export_format = data.get('format', 'csv').lower()
        date_from = data.get('date_from', '')
        date_to = data.get('date_to', '')
        operation_filter = data.get('operation', '')
        
        with get_db() as conn:
            cursor = conn.cursor()
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            where_conditions = []
            params = []
            
            if date_from:
                where_conditions.append("DATE(ol.created_at) >= ?")
                params.append(date_from)
            
            if date_to:
                where_conditions.append("DATE(ol.created_at) <= ?")
                params.append(date_to)
            
            if operation_filter:
                where_conditions.append("ol.operation LIKE ?")
                params.append(f"%{operation_filter}%")
            
            where_clause = ""
            if where_conditions:
                where_clause = "WHERE " + " AND ".join(where_conditions)
            
            # è·å–æ•°æ®
            query = f"""
                SELECT ol.*, u.username 
                FROM operation_logs ol
                LEFT JOIN users u ON ol.user_id = u.id
                {where_clause}
                ORDER BY ol.created_at DESC
                LIMIT 10000
            """
            cursor.execute(query, params)
            logs = cursor.fetchall()
        
        if export_format == 'csv':
            # ç”ŸæˆCSV
            output = StringIO()
            writer = csv.writer(output)
            
            # å†™å…¥æ ‡é¢˜è¡Œ
            writer.writerow(['ID', 'ç”¨æˆ·å', 'æ“ä½œç±»å‹', 'ç›®æ ‡ID', 'åˆ›å»ºæ—¶é—´', 'è¯¦æƒ…'])
            
            # å†™å…¥æ•°æ®è¡Œ
            for log in logs:
                details_data = {}
                try:
                    if log['details']:
                        details_data = json.loads(log['details'])
                except:
                    details_data = {'user_details': log['details']}
                
                writer.writerow([
                    log['id'],
                    log['username'] or 'System',
                    log['operation'],
                    log['target_id'] or '',
                    log['created_at'],
                    details_data.get('user_details', '')
                ])
            
            # è®°å½•å¯¼å‡ºæ“ä½œ
            OperationLogger.log('EXPORT_LOGS', None, f'å¯¼å‡ºæ“ä½œæ—¥å¿—ï¼Œæ ¼å¼: {export_format}, æ¡æ•°: {len(logs)}')
            
            # è¿”å›CSVæ–‡ä»¶
            response = make_response(output.getvalue())
            response.headers['Content-Type'] = 'text/csv; charset=utf-8'
            response.headers['Content-Disposition'] = f'attachment; filename=operation_logs_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
            
            return response
        
        else:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'VALIDATION_ERROR',
                    'message': 'ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼'
                }
            }), 400
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': {
                'code': 'SERVER_ERROR',
                'message': 'å¯¼å‡ºæ—¥å¿—å¤±è´¥',
                'details': str(e)
            }
        }), 500

# è·å–æ”¯æŒçš„é—®é¢˜ç±»å‹
@app.route('/api/question-types', methods=['GET'])
def get_supported_question_types():
    """è·å–ç³»ç»Ÿæ”¯æŒçš„é—®é¢˜ç±»å‹åˆ—è¡¨"""
    try:
        supported_types = question_processor.get_supported_types()
        
        # ä¸ºæ¯ç§ç±»å‹æä¾›è¯¦ç»†ä¿¡æ¯
        type_info = {
            'multiple_choice': {
                'name': 'é€‰æ‹©é¢˜',
                'description': 'å•é€‰æˆ–å¤šé€‰é¢˜ï¼Œç”¨æˆ·ä»é¢„è®¾é€‰é¡¹ä¸­é€‰æ‹©ç­”æ¡ˆ',
                'required_fields': ['question', 'options', 'selected'],
                'optional_fields': ['can_speak']
            },
            'text_input': {
                'name': 'å¡«ç©ºé¢˜',
                'description': 'æ–‡æœ¬è¾“å…¥é¢˜ï¼Œç”¨æˆ·å¡«å†™æ–‡å­—ç­”æ¡ˆ',
                'required_fields': ['question', 'answer'],
                'optional_fields': ['max_length']
            }
        }
        
        result = []
        for type_key in supported_types:
            if type_key in type_info:
                result.append({
                    'type': type_key,
                    **type_info[type_key]
                })
        
        return jsonify({
            'success': True,
            'data': result,
            'total': len(result)
        })
    except Exception as e:
        return jsonify({
            'success': False,
            'error': {
                'code': 'SERVER_ERROR',
                'message': 'è·å–é—®é¢˜ç±»å‹å¤±è´¥',
                'details': str(e)
            }
        }), 500

# æ‰¹é‡å¯¼å‡ºé—®å·æ•°æ® - å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒ Excel å’Œ PDF
@app.route('/api/questionnaires/export', methods=['POST'])
@login_required
def batch_export_questionnaires():
    try:
        from export_utils import export_questionnaires, get_export_filename, get_content_type
        
        data = request.json
        questionnaire_ids = data.get('ids', [])
        export_format = data.get('format', 'csv').lower()
        include_details = data.get('include_details', True)
        
        if not questionnaire_ids:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'VALIDATION_ERROR',
                    'message': 'è¯·é€‰æ‹©è¦å¯¼å‡ºçš„é—®å·'
                }
            }), 400
        
        # éªŒè¯å¯¼å‡ºæ ¼å¼
        supported_formats = ['csv', 'excel', 'xlsx', 'pdf', 'json']
        if export_format not in supported_formats:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'VALIDATION_ERROR',
                    'message': f'ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼ï¼Œæ”¯æŒ: {", ".join(supported_formats)}'
                }
            }), 400
        
        # è·å–é—®å·æ•°æ®
        with get_db() as conn:
            cursor = conn.cursor()
            placeholders = ','.join(['?'] * len(questionnaire_ids))
            cursor.execute(f"SELECT * FROM questionnaires WHERE id IN ({placeholders}) ORDER BY created_at DESC", questionnaire_ids)
            questionnaires = cursor.fetchall()
        
        if not questionnaires:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'NOT_FOUND',
                    'message': 'æœªæ‰¾åˆ°æŒ‡å®šçš„é—®å·æ•°æ®'
                }
            }), 404
        
        # å¤„ç† JSON æ ¼å¼ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        if export_format == 'json':
            result = []
            for q in questionnaires:
                result.append({
                    'id': q['id'],
                    'type': q['type'],
                    'name': q['name'],
                    'grade': q['grade'],
                    'submission_date': q['submission_date'],
                    'created_at': q['created_at'],
                    'updated_at': q['updated_at'],
                    'data': json.loads(q['data'])
                })
            
            filename = get_export_filename('json', 'questionnaires_batch')
            response = make_response(json.dumps(result, default=str, ensure_ascii=False, indent=2))
            response.headers['Content-Disposition'] = f'attachment; filename={filename}'
            response.headers['Content-type'] = 'application/json; charset=utf-8'
            
            # è®°å½•æ“ä½œæ—¥å¿—
            OperationLogger.log(OperationLogger.EXPORT_DATA, None, f'æ‰¹é‡å¯¼å‡ºé—®å· {len(questionnaires)} æ¡ (JSONæ ¼å¼)')
            
            return response
        
        # ä½¿ç”¨æ–°çš„å¯¼å‡ºå·¥å…·å¤„ç†å…¶ä»–æ ¼å¼
        try:
            file_content = export_questionnaires(questionnaires, export_format, include_details)
            filename = get_export_filename(export_format, 'questionnaires_batch')
            content_type = get_content_type(export_format)
            
            response = make_response(file_content)
            response.headers['Content-Disposition'] = f'attachment; filename={filename}'
            response.headers['Content-Type'] = content_type
            
            # è®°å½•æ“ä½œæ—¥å¿—
            OperationLogger.log(OperationLogger.EXPORT_DATA, None, 
                         f'æ‰¹é‡å¯¼å‡ºé—®å· {len(questionnaires)} æ¡ ({export_format.upper()}æ ¼å¼)')
            
            return response
            
        except Exception as export_error:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'EXPORT_ERROR',
                    'message': f'å¯¼å‡ºå¤±è´¥: {str(export_error)}',
                    'details': str(export_error)
                }
            }), 500
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': {
                'code': 'SERVER_ERROR',
                'message': 'æ‰¹é‡å¯¼å‡ºå¤±è´¥',
                'details': str(e)
            }
        }), 500

# å¯¼å‡ºå•ä¸ªé—®å·æ•°æ® - å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒå¤šç§æ ¼å¼
@app.route('/api/export/<int:questionnaire_id>', methods=['GET'])
@login_required
def export_questionnaire(questionnaire_id):
    try:
        from export_utils import export_questionnaires, get_export_filename, get_content_type
        
        # è·å–å¯¼å‡ºæ ¼å¼å‚æ•°
        export_format = request.args.get('format', 'csv').lower()
        include_details = request.args.get('include_details', 'true').lower() == 'true'
        
        # éªŒè¯å¯¼å‡ºæ ¼å¼
        supported_formats = ['csv', 'excel', 'xlsx', 'pdf', 'json']
        if export_format not in supported_formats:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'VALIDATION_ERROR',
                    'message': f'ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼ï¼Œæ”¯æŒ: {", ".join(supported_formats)}'
                }
            }), 400
        
        with get_db() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM questionnaires WHERE id = ?", (questionnaire_id,))
            q = cursor.fetchone()
        
        if not q:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'NOT_FOUND',
                    'message': 'é—®å·ä¸å­˜åœ¨'
                }
            }), 404
        
        # å¤„ç† JSON æ ¼å¼ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        if export_format == 'json':
            result = {
                'id': q['id'],
                'type': q['type'],
                'name': q['name'],
                'grade': q['grade'],
                'submission_date': q['submission_date'],
                'created_at': q['created_at'],
                'updated_at': q['updated_at'],
                'data': json.loads(q['data'])
            }
            
            filename = get_export_filename('json', f'questionnaire_{questionnaire_id}')
            response = make_response(json.dumps(result, default=str, ensure_ascii=False, indent=2))
            response.headers['Content-Disposition'] = f'attachment; filename={filename}'
            response.headers['Content-type'] = 'application/json; charset=utf-8'
            
            # è®°å½•æ“ä½œæ—¥å¿—
            OperationLogger.log(OperationLogger.EXPORT_DATA, questionnaire_id, f'å¯¼å‡ºé—®å· {questionnaire_id} (JSONæ ¼å¼)')
            
            return response
        
        # ä½¿ç”¨æ–°çš„å¯¼å‡ºå·¥å…·å¤„ç†å…¶ä»–æ ¼å¼
        try:
            questionnaires = [q]  # åŒ…è£…æˆåˆ—è¡¨
            file_content = export_questionnaires(questionnaires, export_format, include_details)
            filename = get_export_filename(export_format, f'questionnaire_{questionnaire_id}')
            content_type = get_content_type(export_format)
            
            response = make_response(file_content)
            response.headers['Content-Disposition'] = f'attachment; filename={filename}'
            response.headers['Content-Type'] = content_type
            
            # è®°å½•æ“ä½œæ—¥å¿—
            OperationLogger.log(OperationLogger.EXPORT_DATA, questionnaire_id, 
                         f'å¯¼å‡ºé—®å· {questionnaire_id} ({export_format.upper()}æ ¼å¼)')
            
            return response
            
        except Exception as export_error:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'EXPORT_ERROR',
                    'message': f'å¯¼å‡ºå¤±è´¥: {str(export_error)}',
                    'details': str(export_error)
                }
            }), 500
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': {
                'code': 'SERVER_ERROR',
                'message': 'å¯¼å‡ºé—®å·å¤±è´¥',
                'details': str(e)
            }
        }), 500

# é«˜çº§å¯¼å‡ºåŠŸèƒ½ - æ”¯æŒå…¨é‡å¯¼å‡ºå’Œè‡ªå®šä¹‰ç­›é€‰
@app.route('/api/admin/export/advanced', methods=['POST'])
@admin_required
def advanced_export():
    """é«˜çº§å¯¼å‡ºåŠŸèƒ½ï¼Œæ”¯æŒå…¨é‡å¯¼å‡ºå’Œè‡ªå®šä¹‰ç­›é€‰æ¡ä»¶"""
    try:
        from export_utils import export_questionnaires, get_export_filename, get_content_type
        
        data = request.json or {}
        export_format = data.get('format', 'csv').lower()
        include_details = data.get('include_details', True)
        
        # ç­›é€‰æ¡ä»¶
        filters = data.get('filters', {})
        date_from = filters.get('date_from', '')
        date_to = filters.get('date_to', '')
        questionnaire_type = filters.get('type', '')
        grade = filters.get('grade', '')
        name_search = filters.get('name_search', '')
        
        # éªŒè¯å¯¼å‡ºæ ¼å¼
        supported_formats = ['csv', 'excel', 'xlsx', 'pdf']
        if export_format not in supported_formats:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'VALIDATION_ERROR',
                    'message': f'ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼ï¼Œæ”¯æŒ: {", ".join(supported_formats)}'
                }
            }), 400
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        where_conditions = []
        params = []
        
        if date_from:
            where_conditions.append("DATE(created_at) >= ?")
            params.append(date_from)
        
        if date_to:
            where_conditions.append("DATE(created_at) <= ?")
            params.append(date_to)
        
        if questionnaire_type:
            where_conditions.append("type = ?")
            params.append(questionnaire_type)
        
        if grade:
            where_conditions.append("grade LIKE ?")
            params.append(f"%{grade}%")
        
        if name_search:
            where_conditions.append("name LIKE ?")
            params.append(f"%{name_search}%")
        
        # æ„å»ºå®Œæ•´æŸ¥è¯¢
        where_clause = ""
        if where_conditions:
            where_clause = "WHERE " + " AND ".join(where_conditions)
        
        # è·å–é—®å·æ•°æ®
        with get_db() as conn:
            cursor = conn.cursor()
            query = f"SELECT * FROM questionnaires {where_clause} ORDER BY created_at DESC"
            cursor.execute(query, params)
            questionnaires = cursor.fetchall()
        
        if not questionnaires:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'NOT_FOUND',
                    'message': 'æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„é—®å·æ•°æ®'
                }
            }), 404
        
        # æ£€æŸ¥å¯¼å‡ºæ•°é‡é™åˆ¶
        max_export_limit = 1000  # æœ€å¤§å¯¼å‡ºæ•°é‡é™åˆ¶
        if len(questionnaires) > max_export_limit:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'EXPORT_LIMIT_EXCEEDED',
                    'message': f'å¯¼å‡ºæ•°é‡è¶…è¿‡é™åˆ¶ï¼Œæœ€å¤šæ”¯æŒå¯¼å‡º {max_export_limit} æ¡è®°å½•ï¼Œå½“å‰æŸ¥è¯¢ç»“æœ: {len(questionnaires)} æ¡'
                }
            }), 400
        
        # æ‰§è¡Œå¯¼å‡º
        try:
            file_content = export_questionnaires(questionnaires, export_format, include_details)
            filename = get_export_filename(export_format, 'questionnaires_advanced')
            content_type = get_content_type(export_format)
            
            response = make_response(file_content)
            response.headers['Content-Disposition'] = f'attachment; filename={filename}'
            response.headers['Content-Type'] = content_type
            
            # è®°å½•æ“ä½œæ—¥å¿—
            filter_desc = []
            if date_from or date_to:
                filter_desc.append(f"æ—¥æœŸ: {date_from or 'å¼€å§‹'} è‡³ {date_to or 'ç»“æŸ'}")
            if questionnaire_type:
                filter_desc.append(f"ç±»å‹: {questionnaire_type}")
            if grade:
                filter_desc.append(f"å¹´çº§: {grade}")
            if name_search:
                filter_desc.append(f"å§“å: {name_search}")
            
            filter_text = "; ".join(filter_desc) if filter_desc else "æ— ç­›é€‰æ¡ä»¶"
            
            OperationLogger.log(OperationLogger.EXPORT_DATA, None, 
                         f'é«˜çº§å¯¼å‡ºé—®å· {len(questionnaires)} æ¡ ({export_format.upper()}æ ¼å¼) - ç­›é€‰æ¡ä»¶: {filter_text}')
            
            return response
            
        except Exception as export_error:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'EXPORT_ERROR',
                    'message': f'å¯¼å‡ºå¤±è´¥: {str(export_error)}',
                    'details': str(export_error)
                }
            }), 500
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': {
                'code': 'SERVER_ERROR',
                'message': 'é«˜çº§å¯¼å‡ºå¤±è´¥',
                'details': str(e)
            }
        }), 500

# è·å–å¯¼å‡ºé¢„è§ˆä¿¡æ¯
@app.route('/api/admin/export/preview', methods=['POST'])
@admin_required
def export_preview():
    """è·å–å¯¼å‡ºé¢„è§ˆä¿¡æ¯ï¼Œæ˜¾ç¤ºå°†è¦å¯¼å‡ºçš„æ•°æ®ç»Ÿè®¡"""
    try:
        data = request.json or {}
        
        # ç­›é€‰æ¡ä»¶
        filters = data.get('filters', {})
        date_from = filters.get('date_from', '')
        date_to = filters.get('date_to', '')
        questionnaire_type = filters.get('type', '')
        grade = filters.get('grade', '')
        name_search = filters.get('name_search', '')
        
        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        where_conditions = []
        params = []
        
        if date_from:
            where_conditions.append("DATE(created_at) >= ?")
            params.append(date_from)
        
        if date_to:
            where_conditions.append("DATE(created_at) <= ?")
            params.append(date_to)
        
        if questionnaire_type:
            where_conditions.append("type = ?")
            params.append(questionnaire_type)
        
        if grade:
            where_conditions.append("grade LIKE ?")
            params.append(f"%{grade}%")
        
        if name_search:
            where_conditions.append("name LIKE ?")
            params.append(f"%{name_search}%")
        
        # æ„å»ºå®Œæ•´æŸ¥è¯¢
        where_clause = ""
        if where_conditions:
            where_clause = "WHERE " + " AND ".join(where_conditions)
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        with get_db() as conn:
            cursor = conn.cursor()
            
            # æ€»æ•°ç»Ÿè®¡
            count_query = f"SELECT COUNT(*) FROM questionnaires {where_clause}"
            cursor.execute(count_query, params)
            total_count = cursor.fetchone()[0]
            
            # æŒ‰ç±»å‹ç»Ÿè®¡
            type_query = f"SELECT type, COUNT(*) FROM questionnaires {where_clause} GROUP BY type"
            cursor.execute(type_query, params)
            type_stats = dict(cursor.fetchall())
            
            # æŒ‰æ—¥æœŸç»Ÿè®¡ï¼ˆæœ€è¿‘7å¤©ï¼‰
            date_query = f"""
                SELECT DATE(created_at) as date, COUNT(*) 
                FROM questionnaires {where_clause} 
                GROUP BY DATE(created_at) 
                ORDER BY DATE(created_at) DESC 
                LIMIT 7
            """
            cursor.execute(date_query, params)
            date_stats = dict(cursor.fetchall())
        
        return jsonify({
            'success': True,
            'preview': {
                'total_count': total_count,
                'type_statistics': type_stats,
                'date_statistics': date_stats,
                'export_limit': 1000,
                'can_export': total_count <= 1000,
                'filters_applied': {
                    'date_from': date_from,
                    'date_to': date_to,
                    'type': questionnaire_type,
                    'grade': grade,
                    'name_search': name_search
                }
            }
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': {
                'code': 'SERVER_ERROR',
                'message': 'è·å–å¯¼å‡ºé¢„è§ˆå¤±è´¥',
                'details': str(e)
            }
        }), 500

# Frankfurt ScaleæŠ¥å‘Šç”ŸæˆAPI
@app.route('/api/generate_frankfurt_report', methods=['POST'])
@login_required
def generate_frankfurt_report():
    """ç”ŸæˆFrankfurt Scaleé€‰æ‹©æ€§ç¼„é»˜ç­›æŸ¥é‡è¡¨æŠ¥å‘Š"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'INVALID_REQUEST',
                    'message': 'è¯·æ±‚æ•°æ®ä¸èƒ½ä¸ºç©º'
                }
            }), 400
        
        questionnaire_id = data.get('questionnaire_id')
        
        if not questionnaire_id:
            return jsonify({
                'success': False,
                'error': {
                    'code': 'MISSING_PARAMETERS',
                    'message': 'ç¼ºå°‘å¿…è¦å‚æ•°ï¼šquestionnaire_id'
                }
            }), 400
        
        # éªŒè¯é—®å·æ˜¯å¦å­˜åœ¨å¹¶è·å–å®Œæ•´æ•°æ®
        with get_db() as conn:
            cursor = conn.cursor()
            cursor.execute('SELECT * FROM questionnaires WHERE id = ?', (questionnaire_id,))
            questionnaire = cursor.fetchone()
            
            if not questionnaire:
                return jsonify({
                    'success': False,
                    'error': {
                        'code': 'QUESTIONNAIRE_NOT_FOUND',
                        'message': 'é—®å·ä¸å­˜åœ¨'
                    }
                }), 404
            
            # è·å–åˆ—å
            columns = [description[0] for description in cursor.description]
            questionnaire_dict = dict(zip(columns, questionnaire))
            
            if questionnaire_dict['type'] != 'frankfurt_scale_selective_mutism':
                return jsonify({
                    'success': False,
                    'error': {
                        'code': 'INVALID_QUESTIONNAIRE_TYPE',
                        'message': 'é—®å·ç±»å‹ä¸åŒ¹é…ï¼Œåªæ”¯æŒfrankfurt_scale_selective_mutismç±»å‹'
                    }
                }), 400
            
            # ä»é—®å·æ•°æ®ç”ŸæˆæŠ¥å‘Šæ•°æ®
            report_data = generate_frankfurt_report_data(questionnaire_dict)
            
            # ç”ŸæˆæŠ¥å‘ŠHTML
            report_html = generate_frankfurt_report_html(report_data)
            
            # ä¿å­˜æŠ¥å‘Šåˆ°æ•°æ®åº“
            report_json = json.dumps(report_data, ensure_ascii=False)
            cursor.execute(
                'UPDATE questionnaires SET report_data = ?, report_generated_at = ? WHERE id = ?',
                (report_json, datetime.now().isoformat(), questionnaire_id)
            )
            conn.commit()
            
            return jsonify({
                'success': True,
                'data': {
                    'questionnaire_id': questionnaire_id,
                    'report_html': report_html,
                    'report_data': report_data,
                    'generated_at': datetime.now().isoformat()
                }
            })
            
    except Exception as e:
        return jsonify({
            'success': False,
            'error': {
                'code': 'SERVER_ERROR',
                'message': 'ç”ŸæˆæŠ¥å‘Šå¤±è´¥',
                'details': str(e)
            }
        }), 500

def generate_frankfurt_report_data(questionnaire_dict):
    """ä»é—®å·æ•°æ®ç”ŸæˆFrankfurt ScaleæŠ¥å‘Šæ•°æ®"""
    try:
        # è§£æé—®å·æ•°æ®
        data = json.loads(questionnaire_dict.get('data', '{}'))
        basic_info = data.get('basic_info', {})
        questions = data.get('questions', [])
        
        # åˆå§‹åŒ–æŠ¥å‘Šæ•°æ®
        report_data = {
            'basic_info': {
                'name': basic_info.get('name', questionnaire_dict.get('name', 'æœªçŸ¥')),
                'gender': basic_info.get('gender', 'æœªçŸ¥'),
                'age': basic_info.get('age', 'æœªçŸ¥'),
                'birthdate': basic_info.get('birthdate', basic_info.get('birth_date', 'æœªçŸ¥'))
            },
            'scores': {
                'ds_total': 0,
                'ss_total': 0,
                'ds_average': 0,
                'ss_average': 0,
                'ss_school_total': 0,
                'ss_school_average': 0,
                'ss_public_total': 0,
                'ss_public_average': 0,
                'ss_home_total': 0,
                'ss_home_average': 0
            },
            'risk_assessment': {
                'overall': {
                    'level': 'ä½é£é™©',
                    'color': '#28a745',
                    'description': ''
                },
                'school': {
                    'level': 'ä½é£é™©',
                    'color': '#28a745',
                    'description': '',
                    'score': 0
                },
                'public': {
                    'level': 'ä½é£é™©',
                    'color': '#28a745',
                    'description': '',
                    'score': 0
                },
                'home': {
                    'level': 'ä½é£é™©',
                    'color': '#28a745',
                    'description': '',
                    'score': 0
                }
            },
            'interventions': [],
            'exposure_hierarchy': []
        }
        
        # è®¡ç®—DSå’ŒSSå¾—åˆ†
        ds_count = 0
        ss_count = 0
        ss_school_count = 0
        ss_public_count = 0
        ss_home_count = 0
        
        for question in questions:
            if isinstance(question, dict):
                section = question.get('section', '')
                selected = question.get('selected', [])
                
                # è·å–é€‰ä¸­çš„åˆ†æ•°
                score = 0
                if selected and len(selected) > 0:
                    try:
                        score = int(selected[0])
                    except (ValueError, TypeError):
                        score = 0
                
                # æ ¹æ®sectionå­—æ®µåˆ¤æ–­æ˜¯DSè¿˜æ˜¯SS
                if section == 'DS':
                    report_data['scores']['ds_total'] += score
                    ds_count += 1
                elif section == 'SS_school':
                    report_data['scores']['ss_school_total'] += score
                    report_data['scores']['ss_total'] += score
                    ss_school_count += 1
                    ss_count += 1
                elif section == 'SS_public':
                    report_data['scores']['ss_public_total'] += score
                    report_data['scores']['ss_total'] += score
                    ss_public_count += 1
                    ss_count += 1
                elif section == 'SS_home':
                    report_data['scores']['ss_home_total'] += score
                    report_data['scores']['ss_total'] += score
                    ss_home_count += 1
                    ss_count += 1
        
        # è®¡ç®—å¹³å‡åˆ†
        if ds_count > 0:
            report_data['scores']['ds_average'] = round(report_data['scores']['ds_total'] / ds_count, 2)
        if ss_count > 0:
            report_data['scores']['ss_average'] = round(report_data['scores']['ss_total'] / ss_count, 2)
        if ss_school_count > 0:
            report_data['scores']['ss_school_average'] = round(report_data['scores']['ss_school_total'] / ss_school_count, 2)
        if ss_public_count > 0:
            report_data['scores']['ss_public_average'] = round(report_data['scores']['ss_public_total'] / ss_public_count, 2)
        if ss_home_count > 0:
            report_data['scores']['ss_home_average'] = round(report_data['scores']['ss_home_total'] / ss_home_count, 2)
        
        total_score = report_data['scores']['ds_total'] + report_data['scores']['ss_total']
        
        # æ•´ä½“é£é™©è¯„ä¼°
        if total_score >= 30:
            report_data['risk_assessment']['overall'] = {
                'level': 'é«˜é£é™©',
                'color': '#dc3545',
                'description': 'å»ºè®®ç«‹å³å¯»æ±‚ä¸“ä¸šå¿ƒç†æ²»ç–—å¸ˆçš„å¸®åŠ©'
            }
        elif total_score >= 15:
            report_data['risk_assessment']['overall'] = {
                'level': 'ä¸­ç­‰é£é™©',
                'color': '#ffc107',
                'description': 'å»ºè®®å­¦æ ¡å¿ƒç†å’¨è¯¢å¸ˆä»‹å…¥ï¼Œå®¶é•¿å’Œæ•™å¸ˆéœ€è¦å¯†åˆ‡é…åˆ'
            }
        else:
            report_data['risk_assessment']['overall'] = {
                'level': 'ä½é£é™©',
                'color': '#28a745',
                'description': 'ç»§ç»­è§‚å¯Ÿå’Œæ”¯æŒï¼Œåˆ›é€ ç§¯æçš„äº¤æµç¯å¢ƒ'
            }
        
        # å­¦æ ¡ç¯å¢ƒé£é™©è¯„ä¼°
        school_score = report_data['scores']['ss_school_total']
        report_data['risk_assessment']['school']['score'] = school_score
        if school_score >= 20:
            report_data['risk_assessment']['school'].update({
                'level': 'é«˜é£é™©',
                'color': '#dc3545',
                'description': 'åœ¨å­¦æ ¡ç¯å¢ƒä¸­è¡¨ç°å‡ºä¸¥é‡çš„é€‰æ‹©æ€§ç¼„é»˜ç—‡çŠ¶ï¼Œéœ€è¦å­¦æ ¡å¿ƒç†å’¨è¯¢å¸ˆç«‹å³ä»‹å…¥'
            })
        elif school_score >= 10:
            report_data['risk_assessment']['school'].update({
                'level': 'ä¸­ç­‰é£é™©',
                'color': '#ffc107',
                'description': 'åœ¨å­¦æ ¡ç¯å¢ƒä¸­æœ‰æ˜æ˜¾çš„äº¤æµå›°éš¾ï¼Œå»ºè®®ä¸è€å¸ˆå¯†åˆ‡åˆä½œåˆ¶å®šæ”¯æŒè®¡åˆ’'
            })
        else:
            report_data['risk_assessment']['school'].update({
                'level': 'ä½é£é™©',
                'color': '#28a745',
                'description': 'åœ¨å­¦æ ¡ç¯å¢ƒä¸­è¡¨ç°ç›¸å¯¹è‰¯å¥½ï¼Œç»§ç»­é¼“åŠ±å‚ä¸è¯¾å ‚æ´»åŠ¨'
            })
        
        # å…¬å…±åœºæ‰€/ç¤¾åŒºç¯å¢ƒé£é™©è¯„ä¼°
        public_score = report_data['scores']['ss_public_total']
        report_data['risk_assessment']['public']['score'] = public_score
        if public_score >= 16:
            report_data['risk_assessment']['public'].update({
                'level': 'é«˜é£é™©',
                'color': '#dc3545',
                'description': 'åœ¨å…¬å…±åœºæ‰€è¡¨ç°å‡ºä¸¥é‡çš„ç¤¾äº¤å›é¿ï¼Œéœ€è¦ç³»ç»Ÿæ€§çš„æš´éœ²ç–—æ³•'
            })
        elif public_score >= 8:
            report_data['risk_assessment']['public'].update({
                'level': 'ä¸­ç­‰é£é™©',
                'color': '#ffc107',
                'description': 'åœ¨å…¬å…±åœºæ‰€æœ‰ä¸€å®šçš„äº¤æµå›°éš¾ï¼Œå»ºè®®é€æ­¥å¢åŠ ç¤¾åŒºæ´»åŠ¨å‚ä¸'
            })
        else:
            report_data['risk_assessment']['public'].update({
                'level': 'ä½é£é™©',
                'color': '#28a745',
                'description': 'åœ¨å…¬å…±åœºæ‰€è¡¨ç°è¾ƒå¥½ï¼Œå¯ä»¥é€‚å½“å¢åŠ ç¤¾äº¤æœºä¼š'
            })
        
        # å®¶åº­ç¯å¢ƒé£é™©è¯„ä¼°
        home_score = report_data['scores']['ss_home_total']
        report_data['risk_assessment']['home']['score'] = home_score
        if home_score >= 16:
            report_data['risk_assessment']['home'].update({
                'level': 'é«˜é£é™©',
                'color': '#dc3545',
                'description': 'å³ä½¿åœ¨å®¶åº­ç¯å¢ƒä¸­ä¹Ÿå­˜åœ¨ä¸¥é‡çš„äº¤æµéšœç¢ï¼Œå»ºè®®å®¶åº­æ²»ç–—ä»‹å…¥'
            })
        elif home_score >= 8:
            report_data['risk_assessment']['home'].update({
                'level': 'ä¸­ç­‰é£é™©',
                'color': '#ffc107',
                'description': 'åœ¨å®¶åº­ç¯å¢ƒä¸­æœ‰ä¸€å®šçš„äº¤æµé™åˆ¶ï¼Œå»ºè®®å®¶é•¿å­¦ä¹ æ”¯æŒæ€§æ²Ÿé€šæŠ€å·§'
            })
        else:
            report_data['risk_assessment']['home'].update({
                'level': 'ä½é£é™©',
                'color': '#28a745',
                'description': 'åœ¨å®¶åº­ç¯å¢ƒä¸­è¡¨ç°è‰¯å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªé‡è¦çš„æ”¯æŒåŸºç¡€'
            })
        
        # ç”Ÿæˆç»¼åˆå¹²é¢„å»ºè®®
        interventions = []
        
        # åŸºäºæ•´ä½“é£é™©ç­‰çº§çš„å»ºè®®
        if report_data['risk_assessment']['overall']['level'] == 'é«˜é£é™©':
            interventions.extend([
                'ç«‹å³å¯»æ±‚ä¸“ä¸šå¿ƒç†æ²»ç–—å¸ˆçš„å¸®åŠ©',
                'åˆ¶å®šä¸ªæ€§åŒ–çš„æ²»ç–—è®¡åˆ’',
                'å®¶åº­å’Œå­¦æ ¡éœ€è¦å¯†åˆ‡é…åˆ',
                'è€ƒè™‘è¯ç‰©æ²»ç–—çš„å¯èƒ½æ€§'
            ])
        elif report_data['risk_assessment']['overall']['level'] == 'ä¸­ç­‰é£é™©':
            interventions.extend([
                'å­¦æ ¡å¿ƒç†å’¨è¯¢å¸ˆä»‹å…¥',
                'å®¶é•¿å’Œæ•™å¸ˆå¯†åˆ‡é…åˆ',
                'åˆ›å»ºæ”¯æŒæ€§çš„äº¤æµç¯å¢ƒ',
                'å®šæœŸè¯„ä¼°è¿›å±•æƒ…å†µ'
            ])
        else:
            interventions.extend([
                'ç»§ç»­è§‚å¯Ÿå’Œæ”¯æŒ',
                'åˆ›é€ ç§¯æçš„äº¤æµç¯å¢ƒ',
                'é¼“åŠ±å‚ä¸ç¤¾äº¤æ´»åŠ¨',
                'å®šæœŸå…³æ³¨æƒ…å†µå˜åŒ–'
            ])
        
        # åŸºäºå­¦æ ¡ç¯å¢ƒçš„å…·ä½“å»ºè®®
        if report_data['risk_assessment']['school']['level'] == 'é«˜é£é™©':
            interventions.extend([
                'å­¦æ ¡ç¯å¢ƒï¼šå®‰æ’ä¸“é—¨çš„å¿ƒç†æ”¯æŒè€å¸ˆ',
                'å­¦æ ¡ç¯å¢ƒï¼šåˆ›å»ºå®‰å…¨çš„è¡¨è¾¾ç©ºé—´',
                'å­¦æ ¡ç¯å¢ƒï¼šä¸åŒå­¦å»ºç«‹ä¼™ä¼´æ”¯æŒç³»ç»Ÿ'
            ])
        elif report_data['risk_assessment']['school']['level'] == 'ä¸­ç­‰é£é™©':
            interventions.extend([
                'å­¦æ ¡ç¯å¢ƒï¼šä¸ç­ä¸»ä»»åˆ¶å®šä¸ªæ€§åŒ–æ”¯æŒè®¡åˆ’',
                'å­¦æ ¡ç¯å¢ƒï¼šé¼“åŠ±å‚ä¸å°ç»„æ´»åŠ¨',
                'å­¦æ ¡ç¯å¢ƒï¼šæä¾›éè¨€è¯­è¡¨è¾¾æœºä¼š'
            ])
        
        # åŸºäºå…¬å…±åœºæ‰€çš„å…·ä½“å»ºè®®
        if report_data['risk_assessment']['public']['level'] == 'é«˜é£é™©':
            interventions.extend([
                'ç¤¾åŒºç¯å¢ƒï¼šè¿›è¡Œç³»ç»Ÿæ€§æš´éœ²ç–—æ³•',
                'ç¤¾åŒºç¯å¢ƒï¼šä»ç†Ÿæ‚‰çš„ç¯å¢ƒå¼€å§‹ç»ƒä¹ ',
                'ç¤¾åŒºç¯å¢ƒï¼šå®¶é•¿é™ªåŒå‚ä¸ç¤¾åŒºæ´»åŠ¨'
            ])
        elif report_data['risk_assessment']['public']['level'] == 'ä¸­ç­‰é£é™©':
            interventions.extend([
                'ç¤¾åŒºç¯å¢ƒï¼šé€æ­¥å¢åŠ ç¤¾åŒºæ´»åŠ¨å‚ä¸',
                'ç¤¾åŒºç¯å¢ƒï¼šé€‰æ‹©èˆ’é€‚çš„ç¤¾äº¤åœºæ‰€',
                'ç¤¾åŒºç¯å¢ƒï¼šå»ºç«‹ç¤¾åŒºæ”¯æŒç½‘ç»œ'
            ])
        
        # åŸºäºå®¶åº­ç¯å¢ƒçš„å…·ä½“å»ºè®®
        if report_data['risk_assessment']['home']['level'] == 'é«˜é£é™©':
            interventions.extend([
                'å®¶åº­ç¯å¢ƒï¼šè€ƒè™‘å®¶åº­æ²»ç–—',
                'å®¶åº­ç¯å¢ƒï¼šæ”¹å–„å®¶åº­æ²Ÿé€šæ¨¡å¼',
                'å®¶åº­ç¯å¢ƒï¼šåˆ›å»ºæ— å‹åŠ›çš„è¡¨è¾¾ç©ºé—´'
            ])
        elif report_data['risk_assessment']['home']['level'] == 'ä¸­ç­‰é£é™©':
            interventions.extend([
                'å®¶åº­ç¯å¢ƒï¼šå®¶é•¿å­¦ä¹ æ”¯æŒæ€§æ²Ÿé€šæŠ€å·§',
                'å®¶åº­ç¯å¢ƒï¼šå»ºç«‹è§„å¾‹çš„å®¶åº­äº¤æµæ—¶é—´',
                'å®¶åº­ç¯å¢ƒï¼šé¼“åŠ±å®¶åº­å†…çš„è¡¨è¾¾å°è¯•'
            ])
        
        report_data['interventions'] = interventions
        
        # ç”Ÿæˆæš´éœ²å±‚æ¬¡
        report_data['exposure_hierarchy'] = [
            {'level': 1, 'activity': 'åœ¨å®¶ä¸­ä¸äº²å¯†å®¶äººäº¤è°ˆ', 'difficulty': 'æœ€å®¹æ˜“'},
            {'level': 2, 'activity': 'åœ¨ç†Ÿæ‚‰ç¯å¢ƒä¸­ä¸æœ‹å‹äº¤è°ˆ', 'difficulty': 'å®¹æ˜“'},
            {'level': 3, 'activity': 'åœ¨å°ç»„ä¸­å‘è¨€', 'difficulty': 'ä¸­ç­‰'},
            {'level': 4, 'activity': 'åœ¨è¯¾å ‚ä¸Šå›ç­”é—®é¢˜', 'difficulty': 'å›°éš¾'},
            {'level': 5, 'activity': 'åœ¨é™Œç”Ÿäººé¢å‰è®²è¯', 'difficulty': 'æœ€å›°éš¾'}
        ]
        
        return report_data
        
    except Exception as e:
        # è¿”å›é»˜è®¤æŠ¥å‘Šæ•°æ®
        return {
            'basic_info': {
                'name': questionnaire_dict.get('name', 'æœªçŸ¥'),
                'gender': 'æœªçŸ¥',
                'age': 'æœªçŸ¥',
                'birthdate': 'æœªçŸ¥'
            },
            'scores': {
                'ds_total': 0,
                'ss_total': 0,
                'ds_average': 0,
                'ss_average': 0
            },
            'risk_assessment': {
                'level': 'æ— æ³•è¯„ä¼°',
                'color': '#6c757d',
                'description': f'æ•°æ®è§£æé”™è¯¯: {str(e)}'
            },
            'interventions': ['è¯·è”ç³»ä¸“ä¸šäººå‘˜è¿›è¡Œè¯„ä¼°'],
            'exposure_hierarchy': []
        }

def generate_frankfurt_report_html(report_data):
    """ç”ŸæˆFrankfurt ScaleæŠ¥å‘Šçš„HTMLå†…å®¹"""
    basic_info = report_data.get('basic_info', {})
    scores = report_data.get('scores', {})
    risk_assessment = report_data.get('risk_assessment', {})
    interventions = report_data.get('interventions', [])
    exposure_hierarchy = report_data.get('exposure_hierarchy', [])
    
    html = f"""
    <div class="frankfurt-report">
        <h2>Frankfurt Scaleé€‰æ‹©æ€§ç¼„é»˜ç­›æŸ¥é‡è¡¨ - è¯„ä¼°æŠ¥å‘Š</h2>
        
        <div class="basic-info">
            <h3>åŸºæœ¬ä¿¡æ¯</h3>
            <p><strong>å§“åï¼š</strong>{basic_info.get('name', 'æœªå¡«å†™')}</p>
            <p><strong>æ€§åˆ«ï¼š</strong>{basic_info.get('gender', 'æœªå¡«å†™')}</p>
            <p><strong>å¹´é¾„ï¼š</strong>{basic_info.get('age', 'æœªå¡«å†™')}</p>
            <p><strong>ç”Ÿæ—¥ï¼š</strong>{basic_info.get('birthdate', 'æœªå¡«å†™')}</p>
        </div>
        
        <div class="scores-summary">
            <h3>è¯„åˆ†æ€»ç»“</h3>
            <div class="ds-scores">
                <h4>DSéƒ¨åˆ†ï¼ˆè¯Šæ–­ç—‡çŠ¶ï¼‰</h4>
                <p><strong>æ€»åˆ†ï¼š</strong>{scores.get('ds_total', 0)} (å¹³å‡åˆ†: {scores.get('ds_average', 0)})</p>
            </div>
            <div class="ss-scores">
                <h4>SSéƒ¨åˆ†ï¼ˆæƒ…å¢ƒç‰¹å¼‚æ€§ï¼‰</h4>
                <p><strong>æ€»åˆ†ï¼š</strong>{scores.get('ss_total', 0)} (å¹³å‡åˆ†: {scores.get('ss_average', 0)})</p>
                <div class="ss-breakdown">
                    <p><strong>å­¦æ ¡ç¯å¢ƒï¼š</strong>{scores.get('ss_school_total', 0)} (å¹³å‡åˆ†: {scores.get('ss_school_average', 0)})</p>
                    <p><strong>å…¬å…±åœºæ‰€ï¼š</strong>{scores.get('ss_public_total', 0)} (å¹³å‡åˆ†: {scores.get('ss_public_average', 0)})</p>
                    <p><strong>å®¶åº­ç¯å¢ƒï¼š</strong>{scores.get('ss_home_total', 0)} (å¹³å‡åˆ†: {scores.get('ss_home_average', 0)})</p>
                </div>
            </div>
        </div>
        
        <div class="risk-assessment">
            <h3>é£é™©è¯„ä¼°</h3>
            <div class="overall-risk">
                <h4>æ•´ä½“é£é™©è¯„ä¼°</h4>
                <p style="color: {risk_assessment.get('overall', {}).get('color', '#000')}; font-weight: bold;">
                    é£é™©ç­‰çº§ï¼š{risk_assessment.get('overall', {}).get('level', 'æœªçŸ¥')}
                </p>
                <p>{risk_assessment.get('overall', {}).get('description', '')}</p>
            </div>
            <div class="detailed-risk">
                <h4>åˆ†ç¯å¢ƒé£é™©è¯„ä¼°</h4>
                <div class="school-risk">
                    <p><strong>å­¦æ ¡ç¯å¢ƒï¼š</strong>
                        <span style="color: {risk_assessment.get('school', {}).get('color', '#000')}; font-weight: bold;">
                            {risk_assessment.get('school', {}).get('level', 'æœªçŸ¥')}
                        </span>
                        (å¾—åˆ†: {risk_assessment.get('school', {}).get('score', 0)})
                    </p>

                </div>
                <div class="public-risk">
                    <p><strong>å…¬å…±åœºæ‰€ï¼š</strong>
                        <span style="color: {risk_assessment.get('public', {}).get('color', '#000')}; font-weight: bold;">
                            {risk_assessment.get('public', {}).get('level', 'æœªçŸ¥')}
                        </span>
                        (å¾—åˆ†: {risk_assessment.get('public', {}).get('score', 0)})
                    </p>

                </div>
                <div class="home-risk">
                    <p><strong>å®¶åº­ç¯å¢ƒï¼š</strong>
                        <span style="color: {risk_assessment.get('home', {}).get('color', '#000')}; font-weight: bold;">
                            {risk_assessment.get('home', {}).get('level', 'æœªçŸ¥')}
                        </span>
                        (å¾—åˆ†: {risk_assessment.get('home', {}).get('score', 0)})
                    </p>

                </div>
            </div>
        </div>
        
        <div class="interventions">
            <h3>å¹²é¢„å»ºè®®</h3>
            <ul>
    """
    
    for intervention in interventions:
        html += f"<li>{intervention}</li>"
    
    html += """
            </ul>
        </div>
        
        <div class="exposure-hierarchy">
            <h3>è‡ªä¸»æš´éœ²å±‚çº§</h3>
            <ol>
    """
    
    for item in exposure_hierarchy:
        html += f"<li>{item.get('activity', '')} (éš¾åº¦: {item.get('difficulty', '')})</li>"
    
    html += f"""
            </ol>
        </div>
        
        <div class="report-footer">
        </div>
    </div>
    """
    
    return html

# æ³¨å†Œç»Ÿä¸€é”™è¯¯å¤„ç†å™¨
register_error_handlers(app)

# é…ç½®ä¿¡æ¯API - æä¾›ç»™å‰ç«¯ä½¿ç”¨
@app.route('/api/config', methods=['GET'])
def get_config():
    """è¿”å›å‰ç«¯éœ€è¦çš„é…ç½®ä¿¡æ¯"""
    return jsonify({
        'baseUrl': app.config['BASE_URL'],
        'environment': config_name,
        'debug': app.config.get('DEBUG', False)
    })

# ç®¡ç†é¡µé¢è·¯ç”±
@app.route('/admin')
@login_required
def admin_dashboard():
    return render_template('admin.html')

# ç™»å½•é¡µé¢è·¯ç”±
@app.route('/login')
def login_page():
    # å¦‚æœå·²ç»ç™»å½•ï¼Œé‡å®šå‘åˆ°ç®¡ç†é¡µé¢
    if 'user_id' in session:
        return redirect(url_for('admin_dashboard'))
    return render_template('login.html')

# config.jsæ–‡ä»¶è·¯ç”±
@app.route('/config.js')
def config_js():
    """æä¾›config.jsé…ç½®æ–‡ä»¶"""
    return send_file('../html/config.js', mimetype='application/javascript')

@app.route('/html/FSCM/config.js')
def fscm_config_js():
    """æä¾›FSCMç›®å½•ä¸‹çš„config.jsé…ç½®æ–‡ä»¶"""
    return send_file('../html/config.js', mimetype='application/javascript')

# é™æ€èµ„æºè·¯ç”± - æœ¬åœ°å¼€å‘ç¯å¢ƒä½¿ç”¨Flaskä»£ç†
@app.route('/local_assets/<path:filename>')
def serve_local_assets(filename):
    """æä¾›html/local_assetsç›®å½•ä¸‹çš„é™æ€èµ„æº"""
    return send_file(f'../html/local_assets/{filename}')

@app.route('/favicon.ico')
def favicon():
    """æä¾›favicon"""
    return send_file('../html/favicon.ico')

# é™æ€æ–‡ä»¶ä»£ç†è·¯ç”± - æ”¯æŒå„ç§é™æ€èµ„æº
@app.route('/image/<path:filename>')
def serve_images(filename):
    """æä¾›html/imageç›®å½•ä¸‹çš„å›¾ç‰‡èµ„æº"""
    return send_file(f'../html/image/{filename}')

@app.route('/<path:filename>')
def serve_static_files(filename):
    """æä¾›å…¶ä»–é™æ€æ–‡ä»¶ - ä»…åœ¨æœ¬åœ°å¼€å‘ç¯å¢ƒä½¿ç”¨"""
    # æ£€æŸ¥æ˜¯å¦ä¸ºé™æ€æ–‡ä»¶æ‰©å±•å
    static_extensions = ['.js', '.css', '.png', '.jpg', '.jpeg', '.gif', '.ico', '.svg', 
                        '.woff', '.woff2', '.ttf', '.eot', '.webp', '.json']
    
    if any(filename.lower().endswith(ext) for ext in static_extensions):
        try:
            # é¦–å…ˆå°è¯•ä»htmlç›®å½•æä¾›æ–‡ä»¶
            return send_file(f'../html/{filename}')
        except FileNotFoundError:
            # å¦‚æœhtmlç›®å½•ä¸­æ²¡æœ‰ï¼Œå°è¯•ä»æ ¹ç›®å½•
            try:
                return send_file(f'../{filename}')
            except FileNotFoundError:
                return "File not found", 404
    
    # éé™æ€æ–‡ä»¶è¿”å›404
    return "Not found", 404

# FSCMé¡µé¢è·¯ç”± - æ ¹æ®ç¯å¢ƒåŠ¨æ€è®¾ç½®è·¯ç”±
@app.route('/html/FSCM/')
@app.route('/FSCM/')
def fscm_page():
    """Frankfurt Scaleé€‰æ‹©æ€§ç¼„é»˜ç­›æŸ¥é‡è¡¨é¡µé¢"""
    return send_file('../Frankfurt Scale of Selective Mutism - Integrated.html')

# ç¡®ä¿env-config.jså’Œæœ¬åœ°èµ„æºåœ¨FSCMè·¯å¾„ä¸‹ä¹Ÿèƒ½æ­£ç¡®åŠ è½½
@app.route('/FSCM/html/env-config.js')
def fscm_env_config():
    """åœ¨FSCMè·¯å¾„ä¸‹æä¾›env-config.js"""
    return send_file('../html/env-config.js')

# ç¡®ä¿æœ¬åœ°èµ„æºåœ¨FSCMè·¯å¾„ä¸‹ä¹Ÿèƒ½æ­£ç¡®åŠ è½½
@app.route('/FSCM/html/local_assets/<path:filename>')
def fscm_local_assets(filename):
    """åœ¨FSCMè·¯å¾„ä¸‹æä¾›æœ¬åœ°èµ„æº"""
    return send_file(f'../html/local_assets/{filename}')

# é¦–é¡µè·¯ç”± - htmlç›®å½•ä¸­çš„index.htmlä½œä¸ºå…¥å£é¡µ
@app.route('/')
def index():
    """é¦–é¡µ - è¿”å›htmlç›®å½•ä¸­çš„index.html"""
    return send_file('../html/index.html')

# magic-wireé¡µé¢è·¯ç”±
@app.route('/magic-wire')
def magic_wire():
    """Magic Wireé¡µé¢"""
    return send_file('../html/magic-wire.html')

# studyé¡µé¢è·¯ç”±
@app.route('/study')
def study():
    """Studyé¡µé¢"""
    return send_file('../html/i5.html')

# é—®å·å¼•å¯¼é¡µè·¯ç”±
@app.route('/guide')
def guide():
    """é—®å·å¼•å¯¼é¡µ"""
    return send_file('../å¼•å¯¼é¡µ.html')

# 6å¼ è¡¨å•é¡µé¢è·¯ç”±
@app.route('/å®¶é•¿è®¿è°ˆè¡¨.html')
def parent_interview():
    """å®¶é•¿è®¿è°ˆè¡¨"""
    return send_file('../å®¶é•¿è®¿è°ˆè¡¨.html')

@app.route('/å°å­¦ç”Ÿäº¤æµè¯„å®šè¡¨.html')
def student_communication():
    """å°å­¦ç”Ÿäº¤æµè¯„å®šè¡¨"""
    return send_file('../å°å­¦ç”Ÿäº¤æµè¯„å®šè¡¨.html')

@app.route('/é’å°‘å¹´è®¿è°ˆè¡¨æ ¼.html')
def teen_interview():
    """é’å°‘å¹´è®¿è°ˆè¡¨æ ¼"""
    return send_file('../é’å°‘å¹´è®¿è°ˆè¡¨æ ¼.html')

@app.route('/è¯´è¯ä¹ æƒ¯è®°å½•.html')
def speech_habit():
    """è¯´è¯ä¹ æƒ¯è®°å½•"""
    return send_file('../è¯´è¯ä¹ æƒ¯è®°å½•.html')

@app.route('/å°å­¦ç”ŸæŠ¥å‘Šè¡¨.html')
def student_report():
    """å°å­¦ç”ŸæŠ¥å‘Šè¡¨"""
    return send_file('../å°å­¦ç”ŸæŠ¥å‘Šè¡¨.html')

@app.route('/å¯èƒ½çš„SMç»´æŒå› ç´ æ¸…å•.html')
def sm_factors():
    """å¯èƒ½çš„SMç»´æŒå› ç´ æ¸…å•"""
    return send_file('../å¯èƒ½çš„SMç»´æŒå› ç´ æ¸…å•.html')

if __name__ == '__main__':
    # åˆå§‹åŒ–æ•°æ®åº“
    init_db()
    # å¯åŠ¨Flaskåº”ç”¨
    app.run(debug=True, host='0.0.0.0', port=5002)
# ==================== æ–‡ä»¶APIè·¯ç”± ====================

@app.route('/files/upload', methods=['GET'])
def get_upload_files():
    """è·å–ä¸Šä¼ ç›®å½•æ–‡ä»¶åˆ—è¡¨"""
    try:
        import os
        upload_dir = '/home/ftptest/Downloader/upload'
        if not os.path.exists(upload_dir):
            return jsonify({'error': 'ä¸Šä¼ ç›®å½•ä¸å­˜åœ¨'}), 404
        
        files = []
        for filename in os.listdir(upload_dir):
            file_path = os.path.join(upload_dir, filename)
            if os.path.isfile(file_path):
                stat = os.stat(file_path)
                files.append({
                    'name': filename,
                    'size': stat.st_size,
                    'modified': stat.st_mtime
                })
        
        return jsonify({'files': files})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/files/successful', methods=['GET'])
def get_successful_files():
    """è·å–æˆåŠŸç›®å½•æ–‡ä»¶åˆ—è¡¨"""
    try:
        import os
        successful_dir = '/home/ftptest/Downloader/successful'
        if not os.path.exists(successful_dir):
            return jsonify({'error': 'æˆåŠŸç›®å½•ä¸å­˜åœ¨'}), 404
        
        files = []
        for filename in os.listdir(successful_dir):
            file_path = os.path.join(successful_dir, filename)
            if os.path.isfile(file_path):
                stat = os.stat(file_path)
                files.append({
                    'name': filename,
                    'size': stat.st_size,
                    'modified': stat.st_mtime
                })
        
        return jsonify({'files': files})
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/files/down', methods=['GET'])
def get_down_files():
    """è·å–ä¸‹è½½ç›®å½•æ–‡ä»¶åˆ—è¡¨"""
    try:
        import os
        down_dir = '/home/ftptest/Downloader/down'
        if not os.path.exists(down_dir):
            return jsonify({'error': 'ä¸‹è½½ç›®å½•ä¸å­˜åœ¨'}), 404
        
        files = []
        for filename in os.listdir(down_dir):
            file_path = os.path.join(down_dir, filename)
            if os.path.isfile(file_path):
                stat = os.stat(file_path)
                files.append({
                    'name': filename,
                    'size': stat.st_size,
                    'modified': stat.st_mtime
                })
        
        return jsonify({'files': files})
    except Exception as e:
        return jsonify({'error': str(e)}), 500
